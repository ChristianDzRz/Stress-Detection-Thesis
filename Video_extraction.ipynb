{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 10:53:55.909237: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 10:53:56.879625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input, Concatenate, GRU\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pathlib\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMI_emotions =  pathlib.Path(\"C:/Users/cdr03/Documents/Thesis/dataset/MMI/Emotions\")\n",
    "SEQUENCE_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_recursive(path, format = \".txt\"):\n",
    "    txt_files = set()  # create an empty set to store unique txt file names\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(format):\n",
    "                file_path = os.path.join(root, file)\n",
    "                txt_files.add(file_path)  # add the file path to the set\n",
    "        for dir in dirs:\n",
    "            dir_path = os.path.join(root, dir)\n",
    "            list_files_recursive(dir_path)  # recursively call the function on each subdirectory\n",
    "    return list(txt_files)  # return a list of unique txt file names\n",
    "\n",
    "#MMI_emotion_videos = list_files_recursive(MMI_emotions, \".avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MMI_emotion_videos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39mshape(MMI_emotion_videos)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MMI_emotion_videos' is not defined"
     ]
    }
   ],
   "source": [
    "np.shape(MMI_emotion_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(img, size):\n",
    "    img_array = np.array(img , dtype=\"float32\")/255\n",
    "    img_array = img_array.reshape(size, size, 1)\n",
    "    # Return the numpy array\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 96\n",
    "def detect_and_crop_face(img,resize=None):\n",
    "    # Load the input image\n",
    "    \t\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Load the Haar Cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Crop the image to contain the detected face (if any)\n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        face_image = image[y:y+h, x:x+w]\n",
    "        face_image = cv2.resize(face_image, (size, size))\n",
    "        face_image = image_to_array(face_image, size)\n",
    "    else:\n",
    "        rotated=cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_faces = face_cascade.detectMultiScale(rotated, scaleFactor=1.1, minNeighbors=5)\n",
    "        if len(rotated_faces) > 0:\n",
    "            (x, y, w, h) = rotated_faces[0]\n",
    "            face_image = rotated[y:y+h, x:x+w]\n",
    "            face_image = cv2.resize(face_image, (size, size))\n",
    "            face_image = image_to_array(face_image, size)\n",
    "        else:\n",
    "            face_image = None\n",
    "            print(\"face wasn't detected\")\n",
    "    return face_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/blob/master/Chapter08/ch8_nb1_action_recognition.ipynb\n",
    "video_paths = MMI_emotion_videos\n",
    "print(type(MMI_emotion_videos))\n",
    "IMG_size = (size, size)\n",
    "def frame_generator():\n",
    "    np.random.shuffle(video_paths)\n",
    "    for video_path in video_paths:\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n",
    "        current_frame = 0\n",
    "\n",
    "        label = os.path.basename(video_path)\n",
    "\n",
    "        max_images = SEQUENCE_LENGTH\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            if current_frame % sample_every_frame == 0:\n",
    "                # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n",
    "                face_image_frame = detect_and_crop_face(frame, size)\n",
    "                if face_image_frame is not None:\n",
    "                    max_images -= 1\n",
    "                    yield face_image_frame, video_path \n",
    "                else:\n",
    "                    pass\n",
    "            if max_images == 0:\n",
    "                break\n",
    "            current_frame += 1\n",
    "\n",
    "# `from_generator` might throw a warning, expected to disappear in upcoming versions:\n",
    "# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#for_example_2\n",
    "dataset = tf.data.Dataset.from_generator(frame_generator,\n",
    "             output_types=(tf.float32, tf.string),\n",
    "             output_shapes=((size, size,1), ()))\n",
    "\n",
    "dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CK+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 96\n",
    "def listdirs(rootdir):\n",
    "    list = []\n",
    "    for file in os.listdir(rootdir):\n",
    "        d = os.path.join(rootdir, file)\n",
    "        if os.path.isdir(d):\n",
    "            list.append(d)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cohn-kanade-images/S129', 'cohn-kanade-images/S124', 'cohn-kanade-images/S068', 'cohn-kanade-images/S134', 'cohn-kanade-images/S127', 'cohn-kanade-images/S139', 'cohn-kanade-images/S115', 'cohn-kanade-images/S098', 'cohn-kanade-images/S506', 'cohn-kanade-images/S046', 'cohn-kanade-images/S108', 'cohn-kanade-images/S158', 'cohn-kanade-images/S093', 'cohn-kanade-images/S050', 'cohn-kanade-images/S130', 'cohn-kanade-images/S136', 'cohn-kanade-images/S118', 'cohn-kanade-images/S061', 'cohn-kanade-images/S070', 'cohn-kanade-images/S011', 'cohn-kanade-images/S087', 'cohn-kanade-images/S044', 'cohn-kanade-images/S010', 'cohn-kanade-images/S084', 'cohn-kanade-images/S026', 'cohn-kanade-images/S133', 'cohn-kanade-images/S117', 'cohn-kanade-images/S132', 'cohn-kanade-images/S073', 'cohn-kanade-images/S022', 'cohn-kanade-images/S151', 'cohn-kanade-images/S149', 'cohn-kanade-images/S094', 'cohn-kanade-images/S099', 'cohn-kanade-images/S014', 'cohn-kanade-images/S060', 'cohn-kanade-images/S504', 'cohn-kanade-images/S122', 'cohn-kanade-images/S138', 'cohn-kanade-images/S097', 'cohn-kanade-images/S029', 'cohn-kanade-images/S505', 'cohn-kanade-images/S107', 'cohn-kanade-images/S111', 'cohn-kanade-images/S112', 'cohn-kanade-images/S057', 'cohn-kanade-images/S156', 'cohn-kanade-images/S895', 'cohn-kanade-images/S064', 'cohn-kanade-images/S037', 'cohn-kanade-images/S086', 'cohn-kanade-images/S126', 'cohn-kanade-images/S053', 'cohn-kanade-images/S102', 'cohn-kanade-images/S052', 'cohn-kanade-images/S034', 'cohn-kanade-images/S119', 'cohn-kanade-images/S131', 'cohn-kanade-images/S148', 'cohn-kanade-images/S125', 'cohn-kanade-images/S028', 'cohn-kanade-images/S137', 'cohn-kanade-images/S054', 'cohn-kanade-images/S105', 'cohn-kanade-images/S082', 'cohn-kanade-images/S078', 'cohn-kanade-images/S092', 'cohn-kanade-images/S503', 'cohn-kanade-images/S090', 'cohn-kanade-images/S059', 'cohn-kanade-images/S075', 'cohn-kanade-images/S065', 'cohn-kanade-images/S080', 'cohn-kanade-images/S051', 'cohn-kanade-images/S005', 'cohn-kanade-images/S160', 'cohn-kanade-images/S095', 'cohn-kanade-images/S055', 'cohn-kanade-images/S120', 'cohn-kanade-images/S100', 'cohn-kanade-images/S502', 'cohn-kanade-images/S121', 'cohn-kanade-images/S081', 'cohn-kanade-images/S106', 'cohn-kanade-images/S079', 'cohn-kanade-images/S069', 'cohn-kanade-images/S110', 'cohn-kanade-images/S072', 'cohn-kanade-images/S089', 'cohn-kanade-images/S056', 'cohn-kanade-images/S058', 'cohn-kanade-images/S063', 'cohn-kanade-images/S042', 'cohn-kanade-images/S114', 'cohn-kanade-images/S154', 'cohn-kanade-images/S085', 'cohn-kanade-images/S101', 'cohn-kanade-images/S128', 'cohn-kanade-images/S035', 'cohn-kanade-images/S999', 'cohn-kanade-images/S045', 'cohn-kanade-images/S103', 'cohn-kanade-images/S032', 'cohn-kanade-images/S062', 'cohn-kanade-images/S113', 'cohn-kanade-images/S096', 'cohn-kanade-images/S091', 'cohn-kanade-images/S501', 'cohn-kanade-images/S155', 'cohn-kanade-images/S157', 'cohn-kanade-images/S104', 'cohn-kanade-images/S077', 'cohn-kanade-images/S109', 'cohn-kanade-images/S071', 'cohn-kanade-images/S083', 'cohn-kanade-images/S074', 'cohn-kanade-images/S066', 'cohn-kanade-images/S088', 'cohn-kanade-images/S067', 'cohn-kanade-images/S147', 'cohn-kanade-images/S076', 'cohn-kanade-images/S116', 'cohn-kanade-images/S135']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "CK_sequences_folders = pathlib.Path(\"./cohn-kanade-images/\")\n",
    "IMG_size = (size, size)\n",
    "parent_folder_paths = listdirs(CK_sequences_folders)\n",
    "print(parent_folder_paths)\n",
    "def frame_generator():\n",
    "    np.random.shuffle(parent_folder_paths)\n",
    "    for parent_folder_path in parent_folder_paths:\n",
    "        subfolder_paths = sorted(glob.glob(os.path.join(parent_folder_path, '*')))\n",
    "        for subfolder_path in subfolder_paths:\n",
    "            image_sequence = sorted(glob.glob(os.path.join(subfolder_path, '*.png')))\n",
    "            frames = []\n",
    "            num_frames = len(image_sequence)\n",
    "            if num_frames > SEQUENCE_LENGTH:\n",
    "                image_sequence = image_sequence[(num_frames-SEQUENCE_LENGTH):]\n",
    "\n",
    "            sample_every_frame = 1\n",
    "            current_frame = 0\n",
    "            max_images = SEQUENCE_LENGTH\n",
    "            for image_path in image_sequence:\n",
    "                # Load image using OpenCV\n",
    "                frame = cv2.imread(image_path)\n",
    "                if current_frame % sample_every_frame == 0:\n",
    "                    # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n",
    "                    face_image_frame = detect_and_crop_face(frame, IMG_size)\n",
    "                    if face_image_frame is not None:\n",
    "                        max_images -= 1\n",
    "                        yield face_image_frame, image_path\n",
    "                    else:\n",
    "                        pass\n",
    "                if max_images == 0:\n",
    "                    break\n",
    "                current_frame += 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(frame_generator,\n",
    "             output_types=(tf.float32, tf.string),\n",
    "             output_shapes=((size, size, 1), ()))\n",
    "dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_input_layer(pretrained_model, first_conv, h, w, c):\n",
    "    pretrained_config = pretrained_model.get_config()\n",
    "\n",
    "    # Change the input shape from the model\n",
    "    pretrained_config[\"layers\"][0][\"config\"][\"batch_input_shape\"] = (None, h, w, c)\n",
    "\n",
    "    updated_model = Model.from_config(pretrained_config)\n",
    "\n",
    "\n",
    "    def avg_weights(weights):\n",
    "        average_weights = np.mean(weights, axis=-2).reshape(weights[:, :, -1:, :].shape)\n",
    "        return(average_weights)\n",
    "\n",
    "    pretrained_updated_config = updated_model.get_config()\n",
    "    pretrained_updated_layer_names = [pretrained_updated_config['layers'][x]['name'] for x in range(len(pretrained_updated_config['layers']))]\n",
    "    print(pretrained_updated_layer_names)\n",
    "    first_conv_name = pretrained_updated_layer_names[first_conv]\n",
    "\n",
    "    for layer in pretrained_model.layers:\n",
    "        if layer.name in pretrained_updated_layer_names:\n",
    "            if layer.get_weights() != []:  #All convolutional layers and layers with weights (no input layer or any pool layers)\n",
    "                target_layer = updated_model.get_layer(layer.name)\n",
    "            \n",
    "                if layer.name in first_conv_name:    #For the first convolutionl layer\n",
    "                    weights = layer.get_weights()[0]\n",
    "                    biases  = layer.get_weights()[1]\n",
    "                    \n",
    "                    weights_single_channel = avg_weights(weights)\n",
    "                                                                \n",
    "                    target_layer.set_weights([weights_single_channel, biases])  #Now set weights for the first conv. layer\n",
    "                    target_layer.trainable = False   #You can make this trainable if you want. \n",
    "            \n",
    "                else:\n",
    "                    target_layer.set_weights(layer.get_weights())   #Set weights to all other layers. \n",
    "                    target_layer.trainable = False  #You can make this trainable if you want.\n",
    "    updated_model.summary()\n",
    "    return updated_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_2', 'block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool', 'block5_conv1', 'block5_conv2', 'block5_conv3', 'block5_pool']\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 96, 96, 1)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 96, 96, 64)        640       \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 96, 96, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 48, 48, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 48, 48, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 24, 24, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 24, 24, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,713,536\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,713,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(include_top=False, weights='imagenet')\n",
    "vgg16_updated = change_input_layer(vgg16_model, 1, size, size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vgg16 = Sequential()\n",
    "final_vgg16.add(vgg16_updated)\n",
    "final_vgg16.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_input_layer_dense(pretrained_model, first_conv, h, w, c):\n",
    "    pretrained_config = pretrained_model.get_config()\n",
    "\n",
    "    # Change the input shape from the model\n",
    "    pretrained_config[\"layers\"][0][\"config\"][\"batch_input_shape\"] = (None, h, w, c)\n",
    "\n",
    "    updated_model = Model.from_config(pretrained_config)\n",
    "\n",
    "\n",
    "    def avg_weights(weights):\n",
    "        average_weights = np.mean(weights, axis=-2).reshape(weights[:, :, -1:, :].shape)\n",
    "        return(average_weights)\n",
    "\n",
    "    pretrained_updated_config = updated_model.get_config()\n",
    "    pretrained_updated_layer_names = [pretrained_updated_config['layers'][x]['name'] for x in range(len(pretrained_updated_config['layers']))]\n",
    "    print(pretrained_updated_layer_names)\n",
    "    first_conv_name = pretrained_updated_layer_names[first_conv]\n",
    "\n",
    "    for layer in pretrained_model.layers:\n",
    "        if layer.name in pretrained_updated_layer_names:\n",
    "            if layer.get_weights() != []:  #All convolutional layers and layers with weights (no input layer or any pool layers)\n",
    "                target_layer = updated_model.get_layer(layer.name)\n",
    "            \n",
    "                if layer.name in first_conv_name:    #For the first convolutionl layer\n",
    "                    weights = layer.get_weights()[0]\n",
    "                    \n",
    "                    weights_single_channel = avg_weights(weights)\n",
    "                                                                \n",
    "                    target_layer.set_weights([weights_single_channel])  #Now set weights for the first conv. layer\n",
    "                    target_layer.trainable = False   #You can make this trainable if you want. \n",
    "            \n",
    "                else:\n",
    "                    target_layer.set_weights(layer.get_weights())   #Set weights to all other layers. \n",
    "                    target_layer.trainable = False  #You can make this trainable if you want.\n",
    "    updated_model.summary()\n",
    "    return updated_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_1', 'zero_padding2d', 'conv1/conv', 'conv1/bn', 'conv1/relu', 'zero_padding2d_1', 'pool1', 'conv2_block1_0_bn', 'conv2_block1_0_relu', 'conv2_block1_1_conv', 'conv2_block1_1_bn', 'conv2_block1_1_relu', 'conv2_block1_2_conv', 'conv2_block1_concat', 'conv2_block2_0_bn', 'conv2_block2_0_relu', 'conv2_block2_1_conv', 'conv2_block2_1_bn', 'conv2_block2_1_relu', 'conv2_block2_2_conv', 'conv2_block2_concat', 'conv2_block3_0_bn', 'conv2_block3_0_relu', 'conv2_block3_1_conv', 'conv2_block3_1_bn', 'conv2_block3_1_relu', 'conv2_block3_2_conv', 'conv2_block3_concat', 'conv2_block4_0_bn', 'conv2_block4_0_relu', 'conv2_block4_1_conv', 'conv2_block4_1_bn', 'conv2_block4_1_relu', 'conv2_block4_2_conv', 'conv2_block4_concat', 'conv2_block5_0_bn', 'conv2_block5_0_relu', 'conv2_block5_1_conv', 'conv2_block5_1_bn', 'conv2_block5_1_relu', 'conv2_block5_2_conv', 'conv2_block5_concat', 'conv2_block6_0_bn', 'conv2_block6_0_relu', 'conv2_block6_1_conv', 'conv2_block6_1_bn', 'conv2_block6_1_relu', 'conv2_block6_2_conv', 'conv2_block6_concat', 'pool2_bn', 'pool2_relu', 'pool2_conv', 'pool2_pool', 'conv3_block1_0_bn', 'conv3_block1_0_relu', 'conv3_block1_1_conv', 'conv3_block1_1_bn', 'conv3_block1_1_relu', 'conv3_block1_2_conv', 'conv3_block1_concat', 'conv3_block2_0_bn', 'conv3_block2_0_relu', 'conv3_block2_1_conv', 'conv3_block2_1_bn', 'conv3_block2_1_relu', 'conv3_block2_2_conv', 'conv3_block2_concat', 'conv3_block3_0_bn', 'conv3_block3_0_relu', 'conv3_block3_1_conv', 'conv3_block3_1_bn', 'conv3_block3_1_relu', 'conv3_block3_2_conv', 'conv3_block3_concat', 'conv3_block4_0_bn', 'conv3_block4_0_relu', 'conv3_block4_1_conv', 'conv3_block4_1_bn', 'conv3_block4_1_relu', 'conv3_block4_2_conv', 'conv3_block4_concat', 'conv3_block5_0_bn', 'conv3_block5_0_relu', 'conv3_block5_1_conv', 'conv3_block5_1_bn', 'conv3_block5_1_relu', 'conv3_block5_2_conv', 'conv3_block5_concat', 'conv3_block6_0_bn', 'conv3_block6_0_relu', 'conv3_block6_1_conv', 'conv3_block6_1_bn', 'conv3_block6_1_relu', 'conv3_block6_2_conv', 'conv3_block6_concat', 'conv3_block7_0_bn', 'conv3_block7_0_relu', 'conv3_block7_1_conv', 'conv3_block7_1_bn', 'conv3_block7_1_relu', 'conv3_block7_2_conv', 'conv3_block7_concat', 'conv3_block8_0_bn', 'conv3_block8_0_relu', 'conv3_block8_1_conv', 'conv3_block8_1_bn', 'conv3_block8_1_relu', 'conv3_block8_2_conv', 'conv3_block8_concat', 'conv3_block9_0_bn', 'conv3_block9_0_relu', 'conv3_block9_1_conv', 'conv3_block9_1_bn', 'conv3_block9_1_relu', 'conv3_block9_2_conv', 'conv3_block9_concat', 'conv3_block10_0_bn', 'conv3_block10_0_relu', 'conv3_block10_1_conv', 'conv3_block10_1_bn', 'conv3_block10_1_relu', 'conv3_block10_2_conv', 'conv3_block10_concat', 'conv3_block11_0_bn', 'conv3_block11_0_relu', 'conv3_block11_1_conv', 'conv3_block11_1_bn', 'conv3_block11_1_relu', 'conv3_block11_2_conv', 'conv3_block11_concat', 'conv3_block12_0_bn', 'conv3_block12_0_relu', 'conv3_block12_1_conv', 'conv3_block12_1_bn', 'conv3_block12_1_relu', 'conv3_block12_2_conv', 'conv3_block12_concat', 'pool3_bn', 'pool3_relu', 'pool3_conv', 'pool3_pool', 'conv4_block1_0_bn', 'conv4_block1_0_relu', 'conv4_block1_1_conv', 'conv4_block1_1_bn', 'conv4_block1_1_relu', 'conv4_block1_2_conv', 'conv4_block1_concat', 'conv4_block2_0_bn', 'conv4_block2_0_relu', 'conv4_block2_1_conv', 'conv4_block2_1_bn', 'conv4_block2_1_relu', 'conv4_block2_2_conv', 'conv4_block2_concat', 'conv4_block3_0_bn', 'conv4_block3_0_relu', 'conv4_block3_1_conv', 'conv4_block3_1_bn', 'conv4_block3_1_relu', 'conv4_block3_2_conv', 'conv4_block3_concat', 'conv4_block4_0_bn', 'conv4_block4_0_relu', 'conv4_block4_1_conv', 'conv4_block4_1_bn', 'conv4_block4_1_relu', 'conv4_block4_2_conv', 'conv4_block4_concat', 'conv4_block5_0_bn', 'conv4_block5_0_relu', 'conv4_block5_1_conv', 'conv4_block5_1_bn', 'conv4_block5_1_relu', 'conv4_block5_2_conv', 'conv4_block5_concat', 'conv4_block6_0_bn', 'conv4_block6_0_relu', 'conv4_block6_1_conv', 'conv4_block6_1_bn', 'conv4_block6_1_relu', 'conv4_block6_2_conv', 'conv4_block6_concat', 'conv4_block7_0_bn', 'conv4_block7_0_relu', 'conv4_block7_1_conv', 'conv4_block7_1_bn', 'conv4_block7_1_relu', 'conv4_block7_2_conv', 'conv4_block7_concat', 'conv4_block8_0_bn', 'conv4_block8_0_relu', 'conv4_block8_1_conv', 'conv4_block8_1_bn', 'conv4_block8_1_relu', 'conv4_block8_2_conv', 'conv4_block8_concat', 'conv4_block9_0_bn', 'conv4_block9_0_relu', 'conv4_block9_1_conv', 'conv4_block9_1_bn', 'conv4_block9_1_relu', 'conv4_block9_2_conv', 'conv4_block9_concat', 'conv4_block10_0_bn', 'conv4_block10_0_relu', 'conv4_block10_1_conv', 'conv4_block10_1_bn', 'conv4_block10_1_relu', 'conv4_block10_2_conv', 'conv4_block10_concat', 'conv4_block11_0_bn', 'conv4_block11_0_relu', 'conv4_block11_1_conv', 'conv4_block11_1_bn', 'conv4_block11_1_relu', 'conv4_block11_2_conv', 'conv4_block11_concat', 'conv4_block12_0_bn', 'conv4_block12_0_relu', 'conv4_block12_1_conv', 'conv4_block12_1_bn', 'conv4_block12_1_relu', 'conv4_block12_2_conv', 'conv4_block12_concat', 'conv4_block13_0_bn', 'conv4_block13_0_relu', 'conv4_block13_1_conv', 'conv4_block13_1_bn', 'conv4_block13_1_relu', 'conv4_block13_2_conv', 'conv4_block13_concat', 'conv4_block14_0_bn', 'conv4_block14_0_relu', 'conv4_block14_1_conv', 'conv4_block14_1_bn', 'conv4_block14_1_relu', 'conv4_block14_2_conv', 'conv4_block14_concat', 'conv4_block15_0_bn', 'conv4_block15_0_relu', 'conv4_block15_1_conv', 'conv4_block15_1_bn', 'conv4_block15_1_relu', 'conv4_block15_2_conv', 'conv4_block15_concat', 'conv4_block16_0_bn', 'conv4_block16_0_relu', 'conv4_block16_1_conv', 'conv4_block16_1_bn', 'conv4_block16_1_relu', 'conv4_block16_2_conv', 'conv4_block16_concat', 'conv4_block17_0_bn', 'conv4_block17_0_relu', 'conv4_block17_1_conv', 'conv4_block17_1_bn', 'conv4_block17_1_relu', 'conv4_block17_2_conv', 'conv4_block17_concat', 'conv4_block18_0_bn', 'conv4_block18_0_relu', 'conv4_block18_1_conv', 'conv4_block18_1_bn', 'conv4_block18_1_relu', 'conv4_block18_2_conv', 'conv4_block18_concat', 'conv4_block19_0_bn', 'conv4_block19_0_relu', 'conv4_block19_1_conv', 'conv4_block19_1_bn', 'conv4_block19_1_relu', 'conv4_block19_2_conv', 'conv4_block19_concat', 'conv4_block20_0_bn', 'conv4_block20_0_relu', 'conv4_block20_1_conv', 'conv4_block20_1_bn', 'conv4_block20_1_relu', 'conv4_block20_2_conv', 'conv4_block20_concat', 'conv4_block21_0_bn', 'conv4_block21_0_relu', 'conv4_block21_1_conv', 'conv4_block21_1_bn', 'conv4_block21_1_relu', 'conv4_block21_2_conv', 'conv4_block21_concat', 'conv4_block22_0_bn', 'conv4_block22_0_relu', 'conv4_block22_1_conv', 'conv4_block22_1_bn', 'conv4_block22_1_relu', 'conv4_block22_2_conv', 'conv4_block22_concat', 'conv4_block23_0_bn', 'conv4_block23_0_relu', 'conv4_block23_1_conv', 'conv4_block23_1_bn', 'conv4_block23_1_relu', 'conv4_block23_2_conv', 'conv4_block23_concat', 'conv4_block24_0_bn', 'conv4_block24_0_relu', 'conv4_block24_1_conv', 'conv4_block24_1_bn', 'conv4_block24_1_relu', 'conv4_block24_2_conv', 'conv4_block24_concat', 'pool4_bn', 'pool4_relu', 'pool4_conv', 'pool4_pool', 'conv5_block1_0_bn', 'conv5_block1_0_relu', 'conv5_block1_1_conv', 'conv5_block1_1_bn', 'conv5_block1_1_relu', 'conv5_block1_2_conv', 'conv5_block1_concat', 'conv5_block2_0_bn', 'conv5_block2_0_relu', 'conv5_block2_1_conv', 'conv5_block2_1_bn', 'conv5_block2_1_relu', 'conv5_block2_2_conv', 'conv5_block2_concat', 'conv5_block3_0_bn', 'conv5_block3_0_relu', 'conv5_block3_1_conv', 'conv5_block3_1_bn', 'conv5_block3_1_relu', 'conv5_block3_2_conv', 'conv5_block3_concat', 'conv5_block4_0_bn', 'conv5_block4_0_relu', 'conv5_block4_1_conv', 'conv5_block4_1_bn', 'conv5_block4_1_relu', 'conv5_block4_2_conv', 'conv5_block4_concat', 'conv5_block5_0_bn', 'conv5_block5_0_relu', 'conv5_block5_1_conv', 'conv5_block5_1_bn', 'conv5_block5_1_relu', 'conv5_block5_2_conv', 'conv5_block5_concat', 'conv5_block6_0_bn', 'conv5_block6_0_relu', 'conv5_block6_1_conv', 'conv5_block6_1_bn', 'conv5_block6_1_relu', 'conv5_block6_2_conv', 'conv5_block6_concat', 'conv5_block7_0_bn', 'conv5_block7_0_relu', 'conv5_block7_1_conv', 'conv5_block7_1_bn', 'conv5_block7_1_relu', 'conv5_block7_2_conv', 'conv5_block7_concat', 'conv5_block8_0_bn', 'conv5_block8_0_relu', 'conv5_block8_1_conv', 'conv5_block8_1_bn', 'conv5_block8_1_relu', 'conv5_block8_2_conv', 'conv5_block8_concat', 'conv5_block9_0_bn', 'conv5_block9_0_relu', 'conv5_block9_1_conv', 'conv5_block9_1_bn', 'conv5_block9_1_relu', 'conv5_block9_2_conv', 'conv5_block9_concat', 'conv5_block10_0_bn', 'conv5_block10_0_relu', 'conv5_block10_1_conv', 'conv5_block10_1_bn', 'conv5_block10_1_relu', 'conv5_block10_2_conv', 'conv5_block10_concat', 'conv5_block11_0_bn', 'conv5_block11_0_relu', 'conv5_block11_1_conv', 'conv5_block11_1_bn', 'conv5_block11_1_relu', 'conv5_block11_2_conv', 'conv5_block11_concat', 'conv5_block12_0_bn', 'conv5_block12_0_relu', 'conv5_block12_1_conv', 'conv5_block12_1_bn', 'conv5_block12_1_relu', 'conv5_block12_2_conv', 'conv5_block12_concat', 'conv5_block13_0_bn', 'conv5_block13_0_relu', 'conv5_block13_1_conv', 'conv5_block13_1_bn', 'conv5_block13_1_relu', 'conv5_block13_2_conv', 'conv5_block13_concat', 'conv5_block14_0_bn', 'conv5_block14_0_relu', 'conv5_block14_1_conv', 'conv5_block14_1_bn', 'conv5_block14_1_relu', 'conv5_block14_2_conv', 'conv5_block14_concat', 'conv5_block15_0_bn', 'conv5_block15_0_relu', 'conv5_block15_1_conv', 'conv5_block15_1_bn', 'conv5_block15_1_relu', 'conv5_block15_2_conv', 'conv5_block15_concat', 'conv5_block16_0_bn', 'conv5_block16_0_relu', 'conv5_block16_1_conv', 'conv5_block16_1_bn', 'conv5_block16_1_relu', 'conv5_block16_2_conv', 'conv5_block16_concat', 'bn', 'relu']\n",
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 96, 96, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 102, 102, 1)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)            (None, 48, 48, 64)   3136        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalization)  (None, 48, 48, 64)   256         ['conv1/conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)        (None, 48, 48, 64)   0           ['conv1/bn[0][0]']               \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 50, 50, 64)  0           ['conv1/relu[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 24, 24, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 24, 24, 64)  256         ['pool1[0][0]']                  \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activatio  (None, 24, 24, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 24, 24, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 24, 24, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Concatena  (None, 24, 24, 96)  0           ['pool1[0][0]',                  \n",
      " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNormal  (None, 24, 24, 96)  384         ['conv2_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activatio  (None, 24, 24, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 24, 24, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 24, 24, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Concatena  (None, 24, 24, 128)  0          ['conv2_block1_concat[0][0]',    \n",
      " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv2_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activatio  (None, 24, 24, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 24, 24, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 24, 24, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Concatena  (None, 24, 24, 160)  0          ['conv2_block2_concat[0][0]',    \n",
      " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNormal  (None, 24, 24, 160)  640        ['conv2_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activatio  (None, 24, 24, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2D)   (None, 24, 24, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2D)   (None, 24, 24, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Concatena  (None, 24, 24, 192)  0          ['conv2_block3_concat[0][0]',    \n",
      " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNormal  (None, 24, 24, 192)  768        ['conv2_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activatio  (None, 24, 24, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2D)   (None, 24, 24, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2D)   (None, 24, 24, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Concatena  (None, 24, 24, 224)  0          ['conv2_block4_concat[0][0]',    \n",
      " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNormal  (None, 24, 24, 224)  896        ['conv2_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activatio  (None, 24, 24, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2D)   (None, 24, 24, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2D)   (None, 24, 24, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Concatena  (None, 24, 24, 256)  0          ['conv2_block5_concat[0][0]',    \n",
      " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalization)  (None, 24, 24, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)        (None, 24, 24, 256)  0           ['pool2_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)            (None, 24, 24, 128)  32768       ['pool2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling2D)  (None, 12, 12, 128)  0           ['pool2_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 12, 12, 128)  512        ['pool2_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 12, 12, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Concatena  (None, 12, 12, 160)  0          ['pool2_pool[0][0]',             \n",
      " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_0_bn (BatchNormal  (None, 12, 12, 160)  640        ['conv3_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_0_relu (Activatio  (None, 12, 12, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 12, 12, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Concatena  (None, 12, 12, 192)  0          ['conv3_block1_concat[0][0]',    \n",
      " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNormal  (None, 12, 12, 192)  768        ['conv3_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activatio  (None, 12, 12, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 12, 12, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Concatena  (None, 12, 12, 224)  0          ['conv3_block2_concat[0][0]',    \n",
      " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNormal  (None, 12, 12, 224)  896        ['conv3_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activatio  (None, 12, 12, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 12, 12, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Concatena  (None, 12, 12, 256)  0          ['conv3_block3_concat[0][0]',    \n",
      " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activatio  (None, 12, 12, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 12, 12, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Concatena  (None, 12, 12, 288)  0          ['conv3_block4_concat[0][0]',    \n",
      " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNormal  (None, 12, 12, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activatio  (None, 12, 12, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 12, 12, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Concatena  (None, 12, 12, 320)  0          ['conv3_block5_concat[0][0]',    \n",
      " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNormal  (None, 12, 12, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activatio  (None, 12, 12, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 12, 12, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Concatena  (None, 12, 12, 352)  0          ['conv3_block6_concat[0][0]',    \n",
      " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNormal  (None, 12, 12, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activatio  (None, 12, 12, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 12, 12, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Concatena  (None, 12, 12, 384)  0          ['conv3_block7_concat[0][0]',    \n",
      " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNormal  (None, 12, 12, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activatio  (None, 12, 12, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2D)   (None, 12, 12, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2D)   (None, 12, 12, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Concatena  (None, 12, 12, 416)  0          ['conv3_block8_concat[0][0]',    \n",
      " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchNorma  (None, 12, 12, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Activati  (None, 12, 12, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv2D)  (None, 12, 12, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchNorma  (None, 12, 12, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Activati  (None, 12, 12, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_2_conv (Conv2D)  (None, 12, 12, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Concaten  (None, 12, 12, 448)  0          ['conv3_block9_concat[0][0]',    \n",
      " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchNorma  (None, 12, 12, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Activati  (None, 12, 12, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv2D)  (None, 12, 12, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchNorma  (None, 12, 12, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Activati  (None, 12, 12, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv2D)  (None, 12, 12, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Concaten  (None, 12, 12, 480)  0          ['conv3_block10_concat[0][0]',   \n",
      " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchNorma  (None, 12, 12, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Activati  (None, 12, 12, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv2D)  (None, 12, 12, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchNorma  (None, 12, 12, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Activati  (None, 12, 12, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv2D)  (None, 12, 12, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Concaten  (None, 12, 12, 512)  0          ['conv3_block11_concat[0][0]',   \n",
      " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalization)  (None, 12, 12, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)        (None, 12, 12, 512)  0           ['pool3_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)            (None, 12, 12, 256)  131072      ['pool3_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling2D)  (None, 6, 6, 256)    0           ['pool3_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 6, 6, 256)   1024        ['pool3_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 6, 6, 128)    32768       ['conv4_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Concatena  (None, 6, 6, 288)   0           ['pool3_pool[0][0]',             \n",
      " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNormal  (None, 6, 6, 288)   1152        ['conv4_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activatio  (None, 6, 6, 288)   0           ['conv4_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 6, 6, 128)    36864       ['conv4_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_concat (Concatena  (None, 6, 6, 320)   0           ['conv4_block1_concat[0][0]',    \n",
      " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNormal  (None, 6, 6, 320)   1280        ['conv4_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activatio  (None, 6, 6, 320)   0           ['conv4_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 6, 6, 128)    40960       ['conv4_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Concatena  (None, 6, 6, 352)   0           ['conv4_block2_concat[0][0]',    \n",
      " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNormal  (None, 6, 6, 352)   1408        ['conv4_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activatio  (None, 6, 6, 352)   0           ['conv4_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 6, 6, 128)    45056       ['conv4_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Concatena  (None, 6, 6, 384)   0           ['conv4_block3_concat[0][0]',    \n",
      " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNormal  (None, 6, 6, 384)   1536        ['conv4_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activatio  (None, 6, 6, 384)   0           ['conv4_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 6, 6, 128)    49152       ['conv4_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Concatena  (None, 6, 6, 416)   0           ['conv4_block4_concat[0][0]',    \n",
      " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNormal  (None, 6, 6, 416)   1664        ['conv4_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activatio  (None, 6, 6, 416)   0           ['conv4_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 6, 6, 128)    53248       ['conv4_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Concatena  (None, 6, 6, 448)   0           ['conv4_block5_concat[0][0]',    \n",
      " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNormal  (None, 6, 6, 448)   1792        ['conv4_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activatio  (None, 6, 6, 448)   0           ['conv4_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 6, 6, 128)    57344       ['conv4_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Concatena  (None, 6, 6, 480)   0           ['conv4_block6_concat[0][0]',    \n",
      " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNormal  (None, 6, 6, 480)   1920        ['conv4_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activatio  (None, 6, 6, 480)   0           ['conv4_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 6, 6, 128)    61440       ['conv4_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Concatena  (None, 6, 6, 512)   0           ['conv4_block7_concat[0][0]',    \n",
      " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv4_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activatio  (None, 6, 6, 512)   0           ['conv4_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 6, 6, 128)    65536       ['conv4_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 6, 6, 32)     36864       ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Concatena  (None, 6, 6, 544)   0           ['conv4_block8_concat[0][0]',    \n",
      " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchNorma  (None, 6, 6, 544)   2176        ['conv4_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Activati  (None, 6, 6, 544)   0           ['conv4_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 6, 6, 128)    69632       ['conv4_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Concaten  (None, 6, 6, 576)   0           ['conv4_block9_concat[0][0]',    \n",
      " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchNorma  (None, 6, 6, 576)   2304        ['conv4_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Activati  (None, 6, 6, 576)   0           ['conv4_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 6, 6, 128)    73728       ['conv4_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Concaten  (None, 6, 6, 608)   0           ['conv4_block10_concat[0][0]',   \n",
      " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchNorma  (None, 6, 6, 608)   2432        ['conv4_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Activati  (None, 6, 6, 608)   0           ['conv4_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 6, 6, 128)    77824       ['conv4_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Concaten  (None, 6, 6, 640)   0           ['conv4_block11_concat[0][0]',   \n",
      " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchNorma  (None, 6, 6, 640)   2560        ['conv4_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Activati  (None, 6, 6, 640)   0           ['conv4_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 6, 6, 128)    81920       ['conv4_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Concaten  (None, 6, 6, 672)   0           ['conv4_block12_concat[0][0]',   \n",
      " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchNorma  (None, 6, 6, 672)   2688        ['conv4_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Activati  (None, 6, 6, 672)   0           ['conv4_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 6, 6, 128)    86016       ['conv4_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Concaten  (None, 6, 6, 704)   0           ['conv4_block13_concat[0][0]',   \n",
      " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchNorma  (None, 6, 6, 704)   2816        ['conv4_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Activati  (None, 6, 6, 704)   0           ['conv4_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 6, 6, 128)    90112       ['conv4_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Concaten  (None, 6, 6, 736)   0           ['conv4_block14_concat[0][0]',   \n",
      " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchNorma  (None, 6, 6, 736)   2944        ['conv4_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Activati  (None, 6, 6, 736)   0           ['conv4_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 6, 6, 128)    94208       ['conv4_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Concaten  (None, 6, 6, 768)   0           ['conv4_block15_concat[0][0]',   \n",
      " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchNorma  (None, 6, 6, 768)   3072        ['conv4_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Activati  (None, 6, 6, 768)   0           ['conv4_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 6, 6, 128)    98304       ['conv4_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Concaten  (None, 6, 6, 800)   0           ['conv4_block16_concat[0][0]',   \n",
      " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchNorma  (None, 6, 6, 800)   3200        ['conv4_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Activati  (None, 6, 6, 800)   0           ['conv4_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 6, 6, 128)    102400      ['conv4_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Concaten  (None, 6, 6, 832)   0           ['conv4_block17_concat[0][0]',   \n",
      " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchNorma  (None, 6, 6, 832)   3328        ['conv4_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Activati  (None, 6, 6, 832)   0           ['conv4_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 6, 6, 128)    106496      ['conv4_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Concaten  (None, 6, 6, 864)   0           ['conv4_block18_concat[0][0]',   \n",
      " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchNorma  (None, 6, 6, 864)   3456        ['conv4_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_0_relu (Activati  (None, 6, 6, 864)   0           ['conv4_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 6, 6, 128)    110592      ['conv4_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Concaten  (None, 6, 6, 896)   0           ['conv4_block19_concat[0][0]',   \n",
      " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchNorma  (None, 6, 6, 896)   3584        ['conv4_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Activati  (None, 6, 6, 896)   0           ['conv4_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 6, 6, 128)    114688      ['conv4_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Concaten  (None, 6, 6, 928)   0           ['conv4_block20_concat[0][0]',   \n",
      " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchNorma  (None, 6, 6, 928)   3712        ['conv4_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Activati  (None, 6, 6, 928)   0           ['conv4_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 6, 6, 128)    118784      ['conv4_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Concaten  (None, 6, 6, 960)   0           ['conv4_block21_concat[0][0]',   \n",
      " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchNorma  (None, 6, 6, 960)   3840        ['conv4_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Activati  (None, 6, 6, 960)   0           ['conv4_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 6, 6, 128)    122880      ['conv4_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Concaten  (None, 6, 6, 992)   0           ['conv4_block22_concat[0][0]',   \n",
      " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchNorma  (None, 6, 6, 992)   3968        ['conv4_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Activati  (None, 6, 6, 992)   0           ['conv4_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 6, 6, 128)    126976      ['conv4_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 6, 6, 128)   512         ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 6, 6, 128)   0           ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 6, 6, 32)     36864       ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Concaten  (None, 6, 6, 1024)  0           ['conv4_block23_concat[0][0]',   \n",
      " ate)                                                             'conv4_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalization)  (None, 6, 6, 1024)   4096        ['conv4_block24_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)        (None, 6, 6, 1024)   0           ['pool4_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)            (None, 6, 6, 512)    524288      ['pool4_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling2D)  (None, 3, 3, 512)    0           ['pool4_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 3, 3, 512)   2048        ['pool4_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 3, 3, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Concatena  (None, 3, 3, 544)   0           ['pool4_pool[0][0]',             \n",
      " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNormal  (None, 3, 3, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activatio  (None, 3, 3, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 3, 3, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Concatena  (None, 3, 3, 576)   0           ['conv5_block1_concat[0][0]',    \n",
      " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNormal  (None, 3, 3, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activatio  (None, 3, 3, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 3, 3, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Concatena  (None, 3, 3, 608)   0           ['conv5_block2_concat[0][0]',    \n",
      " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNormal  (None, 3, 3, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activatio  (None, 3, 3, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2D)   (None, 3, 3, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Concatena  (None, 3, 3, 640)   0           ['conv5_block3_concat[0][0]',    \n",
      " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNormal  (None, 3, 3, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activatio  (None, 3, 3, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2D)   (None, 3, 3, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Concatena  (None, 3, 3, 672)   0           ['conv5_block4_concat[0][0]',    \n",
      " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNormal  (None, 3, 3, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activatio  (None, 3, 3, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2D)   (None, 3, 3, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Concatena  (None, 3, 3, 704)   0           ['conv5_block5_concat[0][0]',    \n",
      " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNormal  (None, 3, 3, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activatio  (None, 3, 3, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2D)   (None, 3, 3, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Concatena  (None, 3, 3, 736)   0           ['conv5_block6_concat[0][0]',    \n",
      " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNormal  (None, 3, 3, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activatio  (None, 3, 3, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2D)   (None, 3, 3, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Concatena  (None, 3, 3, 768)   0           ['conv5_block7_concat[0][0]',    \n",
      " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNormal  (None, 3, 3, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activatio  (None, 3, 3, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2D)   (None, 3, 3, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNormal  (None, 3, 3, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activatio  (None, 3, 3, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2D)   (None, 3, 3, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Concatena  (None, 3, 3, 800)   0           ['conv5_block8_concat[0][0]',    \n",
      " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchNorma  (None, 3, 3, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Activati  (None, 3, 3, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv2D)  (None, 3, 3, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchNorma  (None, 3, 3, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Activati  (None, 3, 3, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv2D)  (None, 3, 3, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Concaten  (None, 3, 3, 832)   0           ['conv5_block9_concat[0][0]',    \n",
      " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchNorma  (None, 3, 3, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Activati  (None, 3, 3, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv2D)  (None, 3, 3, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchNorma  (None, 3, 3, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Activati  (None, 3, 3, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv2D)  (None, 3, 3, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Concaten  (None, 3, 3, 864)   0           ['conv5_block10_concat[0][0]',   \n",
      " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchNorma  (None, 3, 3, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Activati  (None, 3, 3, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv2D)  (None, 3, 3, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchNorma  (None, 3, 3, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Activati  (None, 3, 3, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv2D)  (None, 3, 3, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Concaten  (None, 3, 3, 896)   0           ['conv5_block11_concat[0][0]',   \n",
      " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchNorma  (None, 3, 3, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Activati  (None, 3, 3, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv2D)  (None, 3, 3, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchNorma  (None, 3, 3, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Activati  (None, 3, 3, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv2D)  (None, 3, 3, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Concaten  (None, 3, 3, 928)   0           ['conv5_block12_concat[0][0]',   \n",
      " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchNorma  (None, 3, 3, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Activati  (None, 3, 3, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv2D)  (None, 3, 3, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchNorma  (None, 3, 3, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Activati  (None, 3, 3, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv2D)  (None, 3, 3, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Concaten  (None, 3, 3, 960)   0           ['conv5_block13_concat[0][0]',   \n",
      " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchNorma  (None, 3, 3, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Activati  (None, 3, 3, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv2D)  (None, 3, 3, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchNorma  (None, 3, 3, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Activati  (None, 3, 3, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv2D)  (None, 3, 3, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Concaten  (None, 3, 3, 992)   0           ['conv5_block14_concat[0][0]',   \n",
      " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchNorma  (None, 3, 3, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Activati  (None, 3, 3, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv2D)  (None, 3, 3, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchNorma  (None, 3, 3, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Activati  (None, 3, 3, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv2D)  (None, 3, 3, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Concaten  (None, 3, 3, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
      " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " bn (BatchNormalization)        (None, 3, 3, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
      "                                                                                                  \n",
      " relu (Activation)              (None, 3, 3, 1024)   0           ['bn[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,031,232\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,031,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densenet_model = DenseNet121(include_top=False, weights='imagenet')\n",
    "densenet_updated = change_input_layer_dense(densenet_model, 2, size, size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dense = Sequential()\n",
    "final_dense.add(densenet_updated)\n",
    "final_dense.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for image in images:\n",
    "        fd, hog_image = hog(image, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True,channel_axis=-1)\n",
    "        features.append(fd)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def resize_images(images):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_images.append(resize(image, (size, size)))\n",
    "    return np.asarray(resized_images).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 701ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 526ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 541ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 576ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 562ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:07,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 628ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:08,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 547ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:09,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 545ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:11,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 590ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 504ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 564ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:14,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 512ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:16,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 539ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:17,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 644ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 594ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:21,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 537ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 676ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:24,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 619ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:25,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 640ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:27,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 605ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:28,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 638ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:30,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 549ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:31,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 509ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:32,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 615ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:34,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 507ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:35,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 653ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:37,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 529ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:38,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 653ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:40,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 579ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [00:41,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 730ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:43,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 531ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:44,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 542ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:45,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 546ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:47,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 582ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:48,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 599ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:50,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 643ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:51,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 601ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:53,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 531ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:54,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 689ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:55,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 554ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:57,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 621ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:58,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 537ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:59,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 585ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [01:01,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 515ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [01:02,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 655ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [01:03,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 518ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [01:05,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 647ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [01:06,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 567ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:08,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 613ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [01:09,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 523ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:10,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 580ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:11,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [01:13,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 601ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [01:14,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 552ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:15,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 656ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [01:17,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 564ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:18,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 633ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [01:20,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 534ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [01:21,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 619ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [01:22,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 481ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:24,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 633ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [01:25,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 546ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [01:26,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 546ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [01:28,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 621ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [01:29,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 574ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [01:30,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [01:31,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 604ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [01:33,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 566ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:34,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 517ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [01:35,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 590ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [01:37,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 504ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:38,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 533ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [01:40,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 604ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [01:41,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 515ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [01:42,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 541ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [01:44,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 596ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [01:45,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77it [01:46,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 532ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [01:48,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 596ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [01:49,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 542ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [01:51,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 548ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [01:52,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 603ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [01:54,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 518ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [01:55,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 530ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [01:56,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 616ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [01:58,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 538ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86it [01:59,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 516ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [02:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 557ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [02:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 543ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [02:03,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 515ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [02:04,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 648ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [02:05,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 568ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [02:07,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 552ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "93it [02:08,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 592ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [02:09,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 487ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [02:11,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 508ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [02:12,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 654ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [02:13,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 526ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [02:15,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 532ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [02:16,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 703ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:17,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 519ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:19,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 511ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [02:20,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 605ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [02:22,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 537ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [02:23,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 490ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [02:24,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 528ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "106it [02:25,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 492ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107it [02:27,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 603ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [02:28,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 515ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [02:29,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 531ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110it [02:31,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 489ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111it [02:32,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 517ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [02:33,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 613ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113it [02:35,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 527ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114it [02:36,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 575ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "115it [02:37,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 607ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116it [02:39,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 668ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "117it [02:40,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 666ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [02:42,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 638ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [02:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 537ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [02:45,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 590ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [02:46,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 520ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [02:48,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 487ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [02:49,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 593ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [02:50,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 645ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [02:52,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 562ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126it [02:53,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 540ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127it [02:55,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 520ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [02:57,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 569ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "129it [02:58,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 682ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130it [03:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 581ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [03:02,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 730ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132it [03:03,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 592ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "133it [03:05,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 646ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "134it [03:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 620ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [03:08,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 580ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136it [03:09,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 679ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "137it [03:11,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 605ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "138it [03:12,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 639ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [03:14,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 563ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [03:15,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 561ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141it [03:16,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 600ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "142it [03:18,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 701ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [03:20,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 535ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [03:21,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 606ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [03:22,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 545ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [03:24,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 662ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [03:25,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 557ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "148it [03:27,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 520ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "149it [03:28,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 509ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [03:29,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 510ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [03:30,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 638ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [03:32,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 531ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [03:33,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 638ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [03:34,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 532ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [03:36,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 589ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [03:37,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 531ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [03:38,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 523ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158it [03:39,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 633ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159it [03:41,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 551ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [03:42,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 483ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161it [03:43,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 606ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [03:45,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 534ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [03:46,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 529ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [03:47,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 586ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165it [03:49,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 542ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [03:50,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 544ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [03:52,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 576ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [03:53,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 558ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [03:54,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 493ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [03:56,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 625ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [03:57,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 540ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172it [03:58,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 542ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173it [04:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 590ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "174it [04:01,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 513ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [04:03,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 535ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [04:04,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 544ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "177it [04:05,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 627ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "178it [04:07,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 555ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179it [04:08,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 585ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [04:09,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 609ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [04:11,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 545ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [04:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 516ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [04:13,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 633ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [04:15,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 415ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "185it [04:16,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [04:16,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "current_path = None\n",
    "all_features = []\n",
    "files = []\n",
    "folder_save = \"./CK+Sequences_vgg16/\"\n",
    "\n",
    "for img, batch_paths in tqdm.tqdm(dataset):\n",
    "    batch_features = final_vgg16.predict(img)\n",
    "    batch_features = tf.reshape(batch_features, \n",
    "                             (batch_features.shape[0], -1))\n",
    "    \n",
    "    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n",
    "        if os.path.dirname(path) != current_path and current_path is not None:\n",
    "            output_path = folder_save+session[:8]+\".npy\"\n",
    "            np.save(output_path, all_features)\n",
    "            all_features = []\n",
    "            files.append(output_path)\n",
    "        current_path = os.path.dirname(path)\n",
    "        #plt.imshow(features)\n",
    "        #plt.show()\n",
    "        session = os.path.basename(path).decode('utf-8')\n",
    "        all_features.append(features)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4608\n"
     ]
    }
   ],
   "source": [
    "longest_feature = len(max(all_features, key=len))\n",
    "print(longest_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [03:24,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86it [04:27,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face wasn't detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [04:30,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face wasn't detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [06:43,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face wasn't detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [06:47,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "133it [07:35,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n",
      "face wasn't detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [08:18,  3.41s/it]\n"
     ]
    }
   ],
   "source": [
    "current_path = None\n",
    "all_features = []\n",
    "files = []\n",
    "\n",
    "for img, batch_paths in tqdm.tqdm(dataset):\n",
    "    batch_features = final_dense(img)\n",
    "    batch_features = tf.reshape(batch_features, \n",
    "                              (batch_features.shape[0], -1))\n",
    "    \n",
    "    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n",
    "        if path != current_path and current_path is not None:\n",
    "            output_path = current_path.decode().replace('.avi', '.npy')\n",
    "            np.save(output_path, all_features)\n",
    "            all_features = []\n",
    "            files.append(current_path)\n",
    "            \n",
    "        current_path = path\n",
    "        all_features.append(features)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9216\n"
     ]
    }
   ],
   "source": [
    "longest_feature = len(max(all_features, key=len))\n",
    "print(longest_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MMI_Emotions = pd.read_pickle(\"./MMI_emotion_video_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df = pd.DataFrame(files, columns=[\"Path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df[\"Name\"] = files_df[\"Path\"].apply(lambda x: x[-12:-4].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S032-002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S036-002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S050-003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S050-006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S001-115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S039-003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S040-007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S053-018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S045-007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...</td>\n",
       "      <td>S032-011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Path      Name\n",
       "0    b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S032-002\n",
       "1    b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S036-002\n",
       "2    b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S050-003\n",
       "3    b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S050-006\n",
       "4    b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S001-115\n",
       "..                                                 ...       ...\n",
       "229  b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S039-003\n",
       "230  b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S040-007\n",
       "231  b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S053-018\n",
       "232  b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S045-007\n",
       "233  b'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset...  S032-011\n",
       "\n",
       "[234 rows x 2 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df[\"Path\"] = files_df[\"Path\"].apply(lambda x: x.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMI_Emotions_labels = pd.merge(MMI_Emotions, files_df, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(MMI_Emotions_labels['Path'], MMI_Emotions_labels['Emotion'], test_size=0.2, random_state=12, stratify=MMI_Emotions_labels['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_list()\n",
    "X_val = X_val.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1804\\\\S031-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1928\\\\S045-012.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1809\\\\S032-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1855\\\\S036-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1950\\\\S047-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1826\\\\S033-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1764\\\\S021-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1879\\\\S039-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2017\\\\S053-013.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\575\\\\S005-105.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\217\\\\S002-099.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1835\\\\S034-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1956\\\\S047-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1926\\\\S045-010.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\223\\\\S002-105.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1872\\\\S038-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1818\\\\S032-010.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1825\\\\S033-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1769\\\\S028-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1927\\\\S045-011.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1985\\\\S049-014.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1864\\\\S037-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1925\\\\S045-009.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1862\\\\S037-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1771\\\\S028-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1930\\\\S046-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1970\\\\S048-009.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1794\\\\S030-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1870\\\\S038-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1911\\\\S043-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\686\\\\S006-108.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1994\\\\S050-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\350\\\\S003-106.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1975\\\\S049-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1940\\\\S046-011.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1903\\\\S042-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1897\\\\S041-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1763\\\\S021-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1838\\\\S035-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1953\\\\S047-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1856\\\\S036-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1881\\\\S040-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1999\\\\S050-011.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\346\\\\S003-102.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1811\\\\S032-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\104\\\\S001-104.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1948\\\\S046-019.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1959\\\\S047-010.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1834\\\\S034-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1829\\\\S033-010.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\105\\\\S001-105.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\100\\\\S001-100.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1960\\\\S047-011.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1820\\\\S033-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1967\\\\S048-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1929\\\\S045-013.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1966\\\\S048-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\235\\\\S002-117.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1863\\\\S037-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1978\\\\S049-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\116\\\\S001-116.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2002\\\\S050-014.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1986\\\\S049-015.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2001\\\\S050-013.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1860\\\\S037-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1932\\\\S046-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1951\\\\S047-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1807\\\\S031-008.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1993\\\\S050-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1992\\\\S050-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1803\\\\S031-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1841\\\\S035-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1827\\\\S033-008.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1878\\\\S039-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1792\\\\S030-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1888\\\\S040-009.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1875\\\\S039-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2003\\\\S050-015.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1935\\\\S046-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1877\\\\S039-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1852\\\\S036-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1910\\\\S043-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1821\\\\S033-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2007\\\\S053-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1919\\\\S045-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1853\\\\S036-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1805\\\\S031-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1906\\\\S042-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1830\\\\S033-011.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1500\\\\S016-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1946\\\\S046-017.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\115\\\\S001-115.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1831\\\\S034-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2053\\\\S054-023.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1802\\\\S031-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1859\\\\S037-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1923\\\\S045-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1963\\\\S048-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1839\\\\S035-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1933\\\\S046-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1837\\\\S034-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1828\\\\S033-009.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2004\\\\S050-016.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2022\\\\S053-018.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2018\\\\S053-014.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1996\\\\S050-008.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1883\\\\S040-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1916\\\\S044-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1931\\\\S046-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1896\\\\S041-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1922\\\\S045-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\576\\\\S005-106.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1971\\\\S048-010.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1991\\\\S050-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1980\\\\S049-009.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\109\\\\S001-109.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1417\\\\S015-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1882\\\\S040-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\221\\\\S002-103.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\232\\\\S002-114.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1914\\\\S044-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1955\\\\S047-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1800\\\\S031-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1979\\\\S049-008.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1977\\\\S049-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1796\\\\S030-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1983\\\\S049-012.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1965\\\\S048-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\225\\\\S002-107.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1899\\\\S041-008.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1934\\\\S046-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\117\\\\S001-117.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\236\\\\S002-118.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1886\\\\S040-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2008\\\\S053-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\2009\\\\S053-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1814\\\\S032-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1770\\\\S028-002.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1876\\\\S039-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1920\\\\S045-004.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1898\\\\S041-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1924\\\\S045-008.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1884\\\\S040-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1892\\\\S041-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1889\\\\S040-010.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1806\\\\S031-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\348\\\\S003-104.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1958\\\\S047-009.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1822\\\\S033-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\231\\\\S002-113.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1900\\\\S042-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1816\\\\S032-008.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\222\\\\S002-104.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1961\\\\S047-012.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1964\\\\S048-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1972\\\\S049-001.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1765\\\\S021-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1915\\\\S044-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1939\\\\S046-010.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\114\\\\S001-114.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1921\\\\S045-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1905\\\\S042-006.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\107\\\\S001-107.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1987\\\\S049-016.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1824\\\\S033-005.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1974\\\\S049-003.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1865\\\\S037-007.avi',\n",
       " 'C:\\\\Users\\\\cdr03\\\\Documents\\\\Thesis\\\\dataset\\\\MMI\\\\Emotions\\\\1943\\\\S046-014.avi']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(np.array(y_train).reshape(-1, 1))\n",
    "y_val = np.array(np.array(y_val).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder.fit_transform(y_train)\n",
    "y_val = onehot_encoder.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "emotions = [1,2,3,4,5,6]\n",
    "onehot_encoder = LabelBinarizer(sparse_output=False)\n",
    "encoder = onehot_encoder.fit(emotions)\n",
    "\n",
    "\n",
    "def make_generator(file_list, label_list):\n",
    "    def generator():\n",
    "        np.random.shuffle(file_list)\n",
    "        for path, label in zip(file_list, label_list):\n",
    "            full_path = path.replace('.avi', '.npy')\n",
    "            features = np.load(full_path)\n",
    "\n",
    "            padded_sequence = np.zeros((SEQUENCE_LENGTH, longest_feature))\n",
    "            padded_sequence[0:len(features)] = np.array(features)\n",
    "            yield padded_sequence, label\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(make_generator(X_train,y_train),\n",
    "                 output_types=(tf.float32, tf.int16),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, longest_feature), (len(emotions))))\n",
    "train_dataset = train_dataset.batch(8).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(make_generator(X_val,y_val),\n",
    "                 output_types=(tf.float32, tf.int16),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, longest_feature), (len(emotions))))\n",
    "valid_dataset = valid_dataset.batch(8).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CK+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "CK_emotion = pd.read_pickle(f\"./CK_Data_96_Emotion_LF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "CK_emotion[\"Name\"] = CK_emotion['Subject'] +\"_\"+ CK_emotion['Number'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "CK_emotion = CK_emotion[CK_emotion.Emotion !=2 ]\n",
    "CK_emotion.Emotion = CK_emotion.Emotion.replace(7,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files_recursive(\"./CK+Sequences_vgg16/\", \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df = pd.DataFrame(files, columns=[\"Path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_df.to_pickle(\"./CK+Sequences/CNN_Emotion_LSTM\")\n",
    "#files_df = pd.read_pickle(\"./CK+sequences/CNN_Emotion_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./CK+Sequences_vgg16/S158_002.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./CK+Sequences_vgg16/S115_003.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./CK+Sequences_vgg16/S056_004.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./CK+Sequences_vgg16/S102_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./CK+Sequences_vgg16/S081_002.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>./CK+Sequences_vgg16/S119_006.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>./CK+Sequences_vgg16/S042_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>./CK+Sequences_vgg16/S128_004.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>./CK+Sequences_vgg16/S052_004.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>./CK+Sequences_vgg16/S105_002.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Path\n",
       "0    ./CK+Sequences_vgg16/S158_002.npy\n",
       "1    ./CK+Sequences_vgg16/S115_003.npy\n",
       "2    ./CK+Sequences_vgg16/S056_004.npy\n",
       "3    ./CK+Sequences_vgg16/S102_009.npy\n",
       "4    ./CK+Sequences_vgg16/S081_002.npy\n",
       "..                                 ...\n",
       "587  ./CK+Sequences_vgg16/S119_006.npy\n",
       "588  ./CK+Sequences_vgg16/S042_001.npy\n",
       "589  ./CK+Sequences_vgg16/S128_004.npy\n",
       "590  ./CK+Sequences_vgg16/S052_004.npy\n",
       "591  ./CK+Sequences_vgg16/S105_002.npy\n",
       "\n",
       "[592 rows x 1 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df['Name'] = files_df[\"Path\"].apply(lambda x: x[-12:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "CK_Emotions_labels = pd.merge(CK_emotion, files_df, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Number</th>\n",
       "      <th>Code</th>\n",
       "      <th>Image</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S032</td>\n",
       "      <td>005</td>\n",
       "      <td>00000016</td>\n",
       "      <td>[[0.5294118, 0.5254902, 0.49803922, 0.39215687...</td>\n",
       "      <td>3</td>\n",
       "      <td>S032_005</td>\n",
       "      <td>./CK+Sequences_vgg16/S032_005.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S108</td>\n",
       "      <td>006</td>\n",
       "      <td>00000020</td>\n",
       "      <td>[[0.13725491, 0.16470589, 0.19215687, 0.133333...</td>\n",
       "      <td>3</td>\n",
       "      <td>S108_006</td>\n",
       "      <td>./CK+Sequences_vgg16/S108_006.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S052</td>\n",
       "      <td>004</td>\n",
       "      <td>00000033</td>\n",
       "      <td>[[0.38431373, 0.39215687, 0.39215687, 0.384313...</td>\n",
       "      <td>5</td>\n",
       "      <td>S052_004</td>\n",
       "      <td>./CK+Sequences_vgg16/S052_004.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S087</td>\n",
       "      <td>007</td>\n",
       "      <td>00000016</td>\n",
       "      <td>[[0.21176471, 0.2, 0.20784314, 0.20784314, 0.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>S087_007</td>\n",
       "      <td>./CK+Sequences_vgg16/S087_007.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S098</td>\n",
       "      <td>004</td>\n",
       "      <td>00000015</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>5</td>\n",
       "      <td>S098_004</td>\n",
       "      <td>./CK+Sequences_vgg16/S098_004.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>S014</td>\n",
       "      <td>005</td>\n",
       "      <td>00000017</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7764706...</td>\n",
       "      <td>5</td>\n",
       "      <td>S014_005</td>\n",
       "      <td>./CK+Sequences_vgg16/S014_005.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>S107</td>\n",
       "      <td>005</td>\n",
       "      <td>00000011</td>\n",
       "      <td>[[0.2509804, 0.26666668, 0.22745098, 0.0705882...</td>\n",
       "      <td>3</td>\n",
       "      <td>S107_005</td>\n",
       "      <td>./CK+Sequences_vgg16/S107_005.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>S060</td>\n",
       "      <td>003</td>\n",
       "      <td>00000018</td>\n",
       "      <td>[[0.31764707, 0.30588236, 0.2901961, 0.2823529...</td>\n",
       "      <td>2</td>\n",
       "      <td>S060_003</td>\n",
       "      <td>./CK+Sequences_vgg16/S060_003.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>S111</td>\n",
       "      <td>001</td>\n",
       "      <td>00000014</td>\n",
       "      <td>[[0.1764706, 0.18039216, 0.16862746, 0.1647058...</td>\n",
       "      <td>2</td>\n",
       "      <td>S111_001</td>\n",
       "      <td>./CK+Sequences_vgg16/S111_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>S034</td>\n",
       "      <td>003</td>\n",
       "      <td>00000027</td>\n",
       "      <td>[[0.22745098, 0.21568628, 0.21568628, 0.203921...</td>\n",
       "      <td>1</td>\n",
       "      <td>S034_003</td>\n",
       "      <td>./CK+Sequences_vgg16/S034_003.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject Number      Code  \\\n",
       "0      S032    005  00000016   \n",
       "1      S108    006  00000020   \n",
       "2      S052    004  00000033   \n",
       "3      S087    007  00000016   \n",
       "4      S098    004  00000015   \n",
       "..      ...    ...       ...   \n",
       "303    S014    005  00000017   \n",
       "304    S107    005  00000011   \n",
       "305    S060    003  00000018   \n",
       "306    S111    001  00000014   \n",
       "307    S034    003  00000027   \n",
       "\n",
       "                                                 Image  Emotion      Name  \\\n",
       "0    [[0.5294118, 0.5254902, 0.49803922, 0.39215687...        3  S032_005   \n",
       "1    [[0.13725491, 0.16470589, 0.19215687, 0.133333...        3  S108_006   \n",
       "2    [[0.38431373, 0.39215687, 0.39215687, 0.384313...        5  S052_004   \n",
       "3    [[0.21176471, 0.2, 0.20784314, 0.20784314, 0.1...        1  S087_007   \n",
       "4    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        5  S098_004   \n",
       "..                                                 ...      ...       ...   \n",
       "303  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7764706...        5  S014_005   \n",
       "304  [[0.2509804, 0.26666668, 0.22745098, 0.0705882...        3  S107_005   \n",
       "305  [[0.31764707, 0.30588236, 0.2901961, 0.2823529...        2  S060_003   \n",
       "306  [[0.1764706, 0.18039216, 0.16862746, 0.1647058...        2  S111_001   \n",
       "307  [[0.22745098, 0.21568628, 0.21568628, 0.203921...        1  S034_003   \n",
       "\n",
       "                                  Path  \n",
       "0    ./CK+Sequences_vgg16/S032_005.npy  \n",
       "1    ./CK+Sequences_vgg16/S108_006.npy  \n",
       "2    ./CK+Sequences_vgg16/S052_004.npy  \n",
       "3    ./CK+Sequences_vgg16/S087_007.npy  \n",
       "4    ./CK+Sequences_vgg16/S098_004.npy  \n",
       "..                                 ...  \n",
       "303  ./CK+Sequences_vgg16/S014_005.npy  \n",
       "304  ./CK+Sequences_vgg16/S107_005.npy  \n",
       "305  ./CK+Sequences_vgg16/S060_003.npy  \n",
       "306  ./CK+Sequences_vgg16/S111_001.npy  \n",
       "307  ./CK+Sequences_vgg16/S034_003.npy  \n",
       "\n",
       "[308 rows x 7 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CK_Emotions_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_stratified_datasets(X, y, test_size=0.1, val_size=0.1, random_state=None):\n",
    "    \"\"\"\n",
    "    Creates three stratified datasets - train, validation, and test - from the input data X and target y.\n",
    "    \n",
    "    Parameters:\n",
    "        X (array-like): The input data.\n",
    "        y (array-like): The target variable.\n",
    "        test_size (float): The proportion of the data to include in the test set.\n",
    "        val_size (float): The proportion of the remaining data to include in the validation set.\n",
    "        random_state (int): Seed for the random number generator.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple containing the train, validation, and test datasets, each as a tuple of input and target variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    \n",
    "    # split remaining data into validation and train sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size/(1-test_size), random_state=random_state, stratify=y_train)\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) =  create_stratified_datasets(CK_Emotions_labels['Path'], CK_Emotions_labels['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_list()\n",
    "X_test = X_test.to_list()\n",
    "X_val = X_val.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longest_feature = 9216 # Densenet\n",
    "#longest_feature = 4608 # VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "emotions = [1,2,3,4,5,6]\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "folder_path = \".\\CK+sequences_vgg16\"\n",
    "\n",
    "\n",
    "def make_generator(file_list, label_list):\n",
    "    def generator():\n",
    "        np.random.shuffle(file_list)\n",
    "        for path, label in zip(file_list,label_list):\n",
    "            features = np.load(path)\n",
    "            \n",
    "            padded_sequence = np.zeros((SEQUENCE_LENGTH, longest_feature))\n",
    "            padded_sequence[0:len(features)] = np.array(features)\n",
    "\n",
    "            #transformed_label = encoder.transform(label)\n",
    "            yield padded_sequence, label\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load(CK_Emotions_labels.Path[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(np.array(y_train).reshape(-1, 1))\n",
    "y_val = np.array(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder.fit_transform(y_train)\n",
    "y_val = onehot_encoder.fit_transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH=5\n",
    "longest_feature = 9216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(make_generator(X_train,y_train),\n",
    "                 output_types=(tf.float32, tf.int32),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, longest_feature), (len(emotions))))\n",
    "train_dataset = train_dataset.batch(16)\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(make_generator(X_val,y_val),\n",
    "                 output_types=(tf.float32, tf.int32),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, longest_feature), (len(emotions))))\n",
    "valid_dataset = valid_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_generator(make_generator(X_test,y_test),\n",
    "                 output_types=(tf.float32, tf.int32),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, longest_feature), (len(emotions))))\n",
    "test_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[7.3728126e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.1868593e-01, 0.0000000e+00],\n",
      "        [6.6871512e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.3644269e-01, 0.0000000e+00],\n",
      "        [6.1044413e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.3400855e-01, 0.0000000e+00],\n",
      "        [6.2345934e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.1622705e-01, 0.0000000e+00],\n",
      "        [6.3427162e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.4143636e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[4.3391702e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.1117979e-01, 0.0000000e+00],\n",
      "        [4.6452367e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 6.8344730e-01, 0.0000000e+00],\n",
      "        [4.6056998e-01, 0.0000000e+00, 6.6965818e-04, ...,\n",
      "         0.0000000e+00, 6.8457574e-01, 0.0000000e+00],\n",
      "        [4.5971212e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 6.8365449e-01, 0.0000000e+00],\n",
      "        [4.5818061e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.1192294e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[8.0024433e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.0287764e-01, 0.0000000e+00],\n",
      "        [8.3512002e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 6.9392836e-01, 0.0000000e+00],\n",
      "        [8.3633840e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.0067620e-01, 0.0000000e+00],\n",
      "        [8.6167985e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 6.9989175e-01, 0.0000000e+00],\n",
      "        [7.8736377e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.2318208e-01, 0.0000000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[5.5586565e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 9.2859304e-01, 0.0000000e+00],\n",
      "        [5.6938422e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 9.2897630e-01, 0.0000000e+00],\n",
      "        [5.5076599e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 9.2499757e-01, 0.0000000e+00],\n",
      "        [5.3410995e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 9.5907736e-01, 0.0000000e+00],\n",
      "        [5.7892549e-01, 0.0000000e+00, 2.7980804e-03, ...,\n",
      "         0.0000000e+00, 9.1551530e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[1.9302006e-01, 0.0000000e+00, 1.8982270e-01, ...,\n",
      "         0.0000000e+00, 6.2982124e-01, 0.0000000e+00],\n",
      "        [2.4957976e-01, 0.0000000e+00, 2.3743278e-01, ...,\n",
      "         0.0000000e+00, 5.7767570e-01, 0.0000000e+00],\n",
      "        [2.8007495e-01, 0.0000000e+00, 2.8964362e-01, ...,\n",
      "         0.0000000e+00, 6.7055309e-01, 0.0000000e+00],\n",
      "        [3.0295295e-01, 0.0000000e+00, 2.9694149e-01, ...,\n",
      "         0.0000000e+00, 7.0351845e-01, 0.0000000e+00],\n",
      "        [3.6198485e-01, 0.0000000e+00, 3.0161759e-01, ...,\n",
      "         0.0000000e+00, 7.6118475e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[2.2339065e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 6.4656669e-01, 0.0000000e+00],\n",
      "        [2.3274603e-01, 0.0000000e+00, 2.6407301e-02, ...,\n",
      "         0.0000000e+00, 6.4739072e-01, 0.0000000e+00],\n",
      "        [1.9288005e-01, 0.0000000e+00, 2.8508067e-02, ...,\n",
      "         2.1862239e-03, 6.8029201e-01, 0.0000000e+00],\n",
      "        [1.6100091e-01, 0.0000000e+00, 9.2146397e-03, ...,\n",
      "         0.0000000e+00, 6.7886657e-01, 0.0000000e+00],\n",
      "        [2.1826224e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.0553720e-01, 0.0000000e+00]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[5.5074811e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.6990497e-01, 0.0000000e+00],\n",
      "        [5.9032583e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.8597069e-01, 0.0000000e+00],\n",
      "        [5.5273092e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.2483391e-01, 0.0000000e+00],\n",
      "        [5.2935195e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.4574327e-01, 0.0000000e+00],\n",
      "        [4.9744910e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.5052768e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[5.6370103e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.1418232e-01, 0.0000000e+00],\n",
      "        [5.8616835e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.3220050e-01, 0.0000000e+00],\n",
      "        [5.3488791e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.9897857e-01, 0.0000000e+00],\n",
      "        [6.1328566e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 8.0613267e-01, 0.0000000e+00],\n",
      "        [6.0237366e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.9889888e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[1.8027276e-01, 0.0000000e+00, 2.6525122e-01, ...,\n",
      "         0.0000000e+00, 8.2161820e-01, 0.0000000e+00],\n",
      "        [1.6996264e-01, 0.0000000e+00, 2.4232590e-01, ...,\n",
      "         0.0000000e+00, 7.7729392e-01, 0.0000000e+00],\n",
      "        [2.2003180e-01, 0.0000000e+00, 1.7122689e-01, ...,\n",
      "         0.0000000e+00, 7.1641684e-01, 0.0000000e+00],\n",
      "        [2.8236711e-01, 0.0000000e+00, 1.0230273e-01, ...,\n",
      "         0.0000000e+00, 7.4596959e-01, 0.0000000e+00],\n",
      "        [3.0095902e-01, 0.0000000e+00, 6.8702251e-02, ...,\n",
      "         0.0000000e+00, 7.2484827e-01, 0.0000000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[8.8727438e-01, 0.0000000e+00, 6.5323859e-02, ...,\n",
      "         0.0000000e+00, 8.6435831e-01, 0.0000000e+00],\n",
      "        [8.7801445e-01, 0.0000000e+00, 6.0656875e-02, ...,\n",
      "         0.0000000e+00, 8.7597895e-01, 0.0000000e+00],\n",
      "        [9.5089149e-01, 0.0000000e+00, 3.4328997e-02, ...,\n",
      "         0.0000000e+00, 8.9945889e-01, 0.0000000e+00],\n",
      "        [9.9824703e-01, 0.0000000e+00, 6.7836046e-04, ...,\n",
      "         0.0000000e+00, 8.8018113e-01, 0.0000000e+00],\n",
      "        [1.2882018e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 8.8568282e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[6.7532766e-01, 0.0000000e+00, 1.0637343e-02, ...,\n",
      "         0.0000000e+00, 6.8235809e-01, 0.0000000e+00],\n",
      "        [6.8711716e-01, 0.0000000e+00, 1.8766880e-02, ...,\n",
      "         0.0000000e+00, 6.8542105e-01, 0.0000000e+00],\n",
      "        [6.6429079e-01, 0.0000000e+00, 4.4208169e-02, ...,\n",
      "         0.0000000e+00, 6.8657464e-01, 0.0000000e+00],\n",
      "        [7.0855373e-01, 0.0000000e+00, 3.3694983e-02, ...,\n",
      "         0.0000000e+00, 6.7620707e-01, 0.0000000e+00],\n",
      "        [6.5785480e-01, 0.0000000e+00, 2.2632658e-02, ...,\n",
      "         0.0000000e+00, 6.8703270e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[3.3493623e-01, 0.0000000e+00, 5.6990772e-02, ...,\n",
      "         0.0000000e+00, 8.5812944e-01, 0.0000000e+00],\n",
      "        [3.6703566e-01, 0.0000000e+00, 2.5342524e-02, ...,\n",
      "         0.0000000e+00, 8.5712326e-01, 0.0000000e+00],\n",
      "        [3.7579060e-01, 0.0000000e+00, 8.2934499e-03, ...,\n",
      "         0.0000000e+00, 8.3257097e-01, 0.0000000e+00],\n",
      "        [4.1929534e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 8.1837714e-01, 0.0000000e+00],\n",
      "        [4.1629255e-01, 0.0000000e+00, 6.3633919e-04, ...,\n",
      "         0.0000000e+00, 8.4446335e-01, 0.0000000e+00]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.7606024 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.80541277, 0.        ],\n",
      "        [0.7525886 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8273423 , 0.        ],\n",
      "        [0.7300497 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8521584 , 0.        ],\n",
      "        [0.7734567 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.88793993, 0.        ],\n",
      "        [0.76697224, 0.        , 0.00716299, ..., 0.        ,\n",
      "         0.89099073, 0.        ]],\n",
      "\n",
      "       [[0.9481523 , 0.        , 0.05482751, ..., 0.        ,\n",
      "         0.73739624, 0.        ],\n",
      "        [0.90690845, 0.        , 0.03401363, ..., 0.        ,\n",
      "         0.71912736, 0.        ],\n",
      "        [0.899841  , 0.        , 0.04863811, ..., 0.        ,\n",
      "         0.7203891 , 0.        ],\n",
      "        [0.9235636 , 0.        , 0.04307488, ..., 0.        ,\n",
      "         0.7038743 , 0.        ],\n",
      "        [0.9078369 , 0.        , 0.05013558, ..., 0.        ,\n",
      "         0.7076587 , 0.        ]],\n",
      "\n",
      "       [[1.0636494 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.63771474, 0.        ],\n",
      "        [1.1682327 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.62848675, 0.        ],\n",
      "        [1.0668457 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6480688 , 0.        ],\n",
      "        [1.1408262 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.63980746, 0.        ],\n",
      "        [1.1385398 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.62788147, 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.30296314, 0.        , 0.        , ..., 0.        ,\n",
      "         0.9116708 , 0.        ],\n",
      "        [0.30855852, 0.        , 0.        , ..., 0.        ,\n",
      "         0.9107965 , 0.        ],\n",
      "        [0.28235462, 0.        , 0.        , ..., 0.        ,\n",
      "         0.92446595, 0.        ],\n",
      "        [0.2774871 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9345773 , 0.        ],\n",
      "        [0.2591942 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9490039 , 0.        ]],\n",
      "\n",
      "       [[0.32969618, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8534343 , 0.        ],\n",
      "        [0.35294712, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8104185 , 0.        ],\n",
      "        [0.37033325, 0.        , 0.        , ..., 0.        ,\n",
      "         0.83128357, 0.        ],\n",
      "        [0.32673168, 0.        , 0.        , ..., 0.        ,\n",
      "         0.83337045, 0.        ],\n",
      "        [0.34547853, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8474673 , 0.        ]],\n",
      "\n",
      "       [[0.6995132 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8223166 , 0.        ],\n",
      "        [0.77054757, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8171105 , 0.        ],\n",
      "        [0.6890754 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8408355 , 0.        ],\n",
      "        [0.77643716, 0.        , 0.        , ..., 0.        ,\n",
      "         0.9016768 , 0.        ],\n",
      "        [0.7274766 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.87837774, 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[1.3012269 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.55845916, 0.        ],\n",
      "        [1.1210706 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.5866835 , 0.        ],\n",
      "        [1.0076087 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6286177 , 0.        ],\n",
      "        [0.97823215, 0.        , 0.        , ..., 0.        ,\n",
      "         0.66771907, 0.        ],\n",
      "        [0.921789  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6719753 , 0.        ]],\n",
      "\n",
      "       [[0.2967346 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.68514514, 0.        ],\n",
      "        [0.33519208, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6656056 , 0.        ],\n",
      "        [0.2833314 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.67497313, 0.        ],\n",
      "        [0.30916053, 0.        , 0.        , ..., 0.        ,\n",
      "         0.64914924, 0.        ],\n",
      "        [0.3131836 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.66262305, 0.        ]],\n",
      "\n",
      "       [[1.1289878 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.5784347 , 0.        ],\n",
      "        [1.1673701 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.616193  , 0.        ],\n",
      "        [1.1458046 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.59877574, 0.        ],\n",
      "        [1.1072209 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.5634501 , 0.        ],\n",
      "        [1.1056147 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.57993174, 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.3276999 , 0.        , 0.09378597, ..., 0.        ,\n",
      "         0.61893684, 0.        ],\n",
      "        [1.4474722 , 0.        , 0.08197144, ..., 0.        ,\n",
      "         0.65093756, 0.        ],\n",
      "        [1.3753175 , 0.        , 0.08274913, ..., 0.        ,\n",
      "         0.6320861 , 0.        ],\n",
      "        [1.3756013 , 0.        , 0.07726324, ..., 0.        ,\n",
      "         0.67669994, 0.        ],\n",
      "        [1.4118817 , 0.        , 0.08684644, ..., 0.        ,\n",
      "         0.627789  , 0.        ]],\n",
      "\n",
      "       [[0.71039796, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7194056 , 0.        ],\n",
      "        [0.8552865 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7146031 , 0.        ],\n",
      "        [0.8158448 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6921953 , 0.        ],\n",
      "        [0.8976289 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.71419823, 0.        ],\n",
      "        [0.84169877, 0.        , 0.        , ..., 0.        ,\n",
      "         0.71379787, 0.        ]],\n",
      "\n",
      "       [[0.15029149, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7020348 , 0.        ],\n",
      "        [0.13830552, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7113076 , 0.        ],\n",
      "        [0.11700463, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7383819 , 0.        ],\n",
      "        [0.05209692, 0.        , 0.0297212 , ..., 0.        ,\n",
      "         0.78911614, 0.        ],\n",
      "        [0.05506152, 0.        , 0.02789086, ..., 0.        ,\n",
      "         0.8254465 , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.5711291 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9563391 , 0.        ],\n",
      "        [0.5549623 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9505534 , 0.        ],\n",
      "        [0.54356813, 0.        , 0.        , ..., 0.        ,\n",
      "         0.91692245, 0.        ],\n",
      "        [0.5477716 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9293238 , 0.        ],\n",
      "        [0.5642096 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9322495 , 0.        ]],\n",
      "\n",
      "       [[0.6135757 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.81774294, 0.        ],\n",
      "        [0.64196175, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8048762 , 0.        ],\n",
      "        [0.65214777, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8028654 , 0.        ],\n",
      "        [0.66829574, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8128597 , 0.        ],\n",
      "        [0.6552981 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8138958 , 0.        ]],\n",
      "\n",
      "       [[0.30561098, 0.        , 0.26002532, ..., 0.        ,\n",
      "         0.5591748 , 0.        ],\n",
      "        [0.31240177, 0.        , 0.30006662, ..., 0.        ,\n",
      "         0.5704096 , 0.        ],\n",
      "        [0.31841528, 0.        , 0.2653662 , ..., 0.        ,\n",
      "         0.58560926, 0.        ],\n",
      "        [0.23179063, 0.        , 0.30679846, ..., 0.        ,\n",
      "         0.565064  , 0.        ],\n",
      "        [0.2749337 , 0.        , 0.23311624, ..., 0.        ,\n",
      "         0.55715555, 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.1669892 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.78819776, 0.        ],\n",
      "        [1.1947669 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7514404 , 0.        ],\n",
      "        [1.1777996 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7875843 , 0.        ],\n",
      "        [1.1877685 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.773503  , 0.        ],\n",
      "        [1.1223915 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.77641726, 0.        ]],\n",
      "\n",
      "       [[0.02252331, 0.        , 0.13057008, ..., 0.        ,\n",
      "         0.75574225, 0.        ],\n",
      "        [0.05159056, 0.        , 0.11041656, ..., 0.        ,\n",
      "         0.7803498 , 0.        ],\n",
      "        [0.02847254, 0.        , 0.10872769, ..., 0.        ,\n",
      "         0.75811374, 0.        ],\n",
      "        [0.        , 0.        , 0.12054166, ..., 0.        ,\n",
      "         0.7265609 , 0.        ],\n",
      "        [0.        , 0.        , 0.12004074, ..., 0.        ,\n",
      "         0.7485219 , 0.        ]],\n",
      "\n",
      "       [[0.28270125, 0.        , 0.01668555, ..., 0.        ,\n",
      "         1.1327016 , 0.        ],\n",
      "        [0.28629   , 0.        , 0.0083968 , ..., 0.        ,\n",
      "         1.1521442 , 0.        ],\n",
      "        [0.28744316, 0.        , 0.01447433, ..., 0.        ,\n",
      "         1.1431854 , 0.        ],\n",
      "        [0.28881076, 0.        , 0.00876331, ..., 0.        ,\n",
      "         1.154474  , 0.        ],\n",
      "        [0.27830178, 0.        , 0.01197916, ..., 0.        ,\n",
      "         1.1181936 , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.6164521 , 0.        , 0.05072564, ..., 0.        ,\n",
      "         0.7951354 , 0.        ],\n",
      "        [0.4541311 , 0.        , 0.08405027, ..., 0.        ,\n",
      "         0.818238  , 0.        ],\n",
      "        [0.42213595, 0.        , 0.05471075, ..., 0.        ,\n",
      "         0.8071699 , 0.        ],\n",
      "        [0.30697352, 0.        , 0.06876898, ..., 0.        ,\n",
      "         0.79804224, 0.        ],\n",
      "        [0.2658597 , 0.        , 0.04702854, ..., 0.        ,\n",
      "         0.78290796, 0.        ]],\n",
      "\n",
      "       [[0.5425193 , 0.        , 0.00370419, ..., 0.        ,\n",
      "         0.8039293 , 0.        ],\n",
      "        [0.6101099 , 0.        , 0.01150513, ..., 0.        ,\n",
      "         0.8176407 , 0.        ],\n",
      "        [0.5470662 , 0.        , 0.01405662, ..., 0.        ,\n",
      "         0.8286519 , 0.        ],\n",
      "        [0.6209878 , 0.        , 0.01787317, ..., 0.        ,\n",
      "         0.8233721 , 0.        ],\n",
      "        [0.5500206 , 0.        , 0.01638269, ..., 0.        ,\n",
      "         0.81812894, 0.        ]],\n",
      "\n",
      "       [[0.3732543 , 0.        , 0.11967489, ..., 0.        ,\n",
      "         0.6771307 , 0.        ],\n",
      "        [0.4525672 , 0.        , 0.04219067, ..., 0.        ,\n",
      "         0.65424305, 0.        ],\n",
      "        [0.7376663 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.67933506, 0.        ],\n",
      "        [0.734408  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6692961 , 0.        ],\n",
      "        [0.6695218 , 0.        , 0.05034664, ..., 0.        ,\n",
      "         0.6596948 , 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.726946  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7351828 , 0.        ],\n",
      "        [0.70497507, 0.        , 0.        , ..., 0.        ,\n",
      "         0.74728316, 0.        ],\n",
      "        [0.7136237 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.74180514, 0.        ],\n",
      "        [0.7555949 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7481637 , 0.        ],\n",
      "        [0.7264102 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.74473596, 0.        ]],\n",
      "\n",
      "       [[0.60122746, 0.        , 0.        , ..., 0.        ,\n",
      "         0.86721313, 0.        ],\n",
      "        [0.6322044 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8664192 , 0.        ],\n",
      "        [0.5524329 , 0.        , 0.02321053, ..., 0.        ,\n",
      "         0.8530089 , 0.        ],\n",
      "        [0.5687201 , 0.        , 0.01485854, ..., 0.        ,\n",
      "         0.85100794, 0.        ],\n",
      "        [0.53489673, 0.        , 0.00925344, ..., 0.        ,\n",
      "         0.8607242 , 0.        ]],\n",
      "\n",
      "       [[1.4073567 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8798833 , 0.        ],\n",
      "        [1.4246459 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.87304664, 0.        ],\n",
      "        [1.3857288 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8898735 , 0.        ],\n",
      "        [1.3565435 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.86249065, 0.        ],\n",
      "        [1.3992854 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.85967124, 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 1, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.3914104 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8577678 , 0.        ],\n",
      "        [0.38303843, 0.        , 0.        , ..., 0.        ,\n",
      "         0.87283546, 0.        ],\n",
      "        [0.34590182, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8520004 , 0.        ],\n",
      "        [0.30802253, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8548368 , 0.        ],\n",
      "        [0.37364793, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8817141 , 0.        ]],\n",
      "\n",
      "       [[1.1962388 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.57032824, 0.        ],\n",
      "        [1.2288479 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.57739663, 0.        ],\n",
      "        [1.2077028 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.5893285 , 0.        ],\n",
      "        [1.2274495 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.595385  , 0.        ],\n",
      "        [1.236619  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.58002925, 0.        ]],\n",
      "\n",
      "       [[0.7314323 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.73630255, 0.        ],\n",
      "        [0.7533064 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.75595635, 0.        ],\n",
      "        [0.7517783 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.74880505, 0.        ],\n",
      "        [0.788869  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.76480997, 0.        ],\n",
      "        [0.7760986 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.77712584, 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.1364095 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.5810874 , 0.        ],\n",
      "        [1.1367111 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.5863137 , 0.        ],\n",
      "        [1.1602862 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.5800685 , 0.        ],\n",
      "        [1.1871873 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.52627534, 0.        ],\n",
      "        [1.1681808 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.5852895 , 0.        ]],\n",
      "\n",
      "       [[0.37007084, 0.        , 0.10087711, ..., 0.        ,\n",
      "         0.8414406 , 0.        ],\n",
      "        [0.35152584, 0.        , 0.08650437, ..., 0.        ,\n",
      "         0.86207324, 0.        ],\n",
      "        [0.32679713, 0.        , 0.15059957, ..., 0.        ,\n",
      "         0.8646093 , 0.        ],\n",
      "        [0.30894372, 0.        , 0.12624997, ..., 0.        ,\n",
      "         0.8406546 , 0.        ],\n",
      "        [0.31046247, 0.        , 0.11159638, ..., 0.        ,\n",
      "         0.8581963 , 0.        ]],\n",
      "\n",
      "       [[0.7867771 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8819035 , 0.        ],\n",
      "        [0.84156126, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8875799 , 0.        ],\n",
      "        [0.89991575, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8987522 , 0.        ],\n",
      "        [0.9610033 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.87592316, 0.        ],\n",
      "        [0.9570056 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.857681  , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.87567365, 0.        , 0.02205724, ..., 0.        ,\n",
      "         0.72341555, 0.        ],\n",
      "        [0.8885375 , 0.        , 0.02588731, ..., 0.        ,\n",
      "         0.73741615, 0.        ],\n",
      "        [0.88808   , 0.        , 0.02771533, ..., 0.        ,\n",
      "         0.7294628 , 0.        ],\n",
      "        [0.8138583 , 0.        , 0.02248126, ..., 0.        ,\n",
      "         0.7369906 , 0.        ],\n",
      "        [0.8135475 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7329893 , 0.        ]],\n",
      "\n",
      "       [[0.7272567 , 0.        , 0.        , ..., 0.00300574,\n",
      "         0.8146222 , 0.        ],\n",
      "        [0.6582815 , 0.        , 0.        , ..., 0.00636902,\n",
      "         0.80921125, 0.        ],\n",
      "        [0.67719245, 0.        , 0.        , ..., 0.        ,\n",
      "         0.80400074, 0.        ],\n",
      "        [0.6547524 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8101127 , 0.        ],\n",
      "        [0.69717675, 0.        , 0.01579392, ..., 0.        ,\n",
      "         0.8223518 , 0.        ]],\n",
      "\n",
      "       [[0.459851  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.56789434, 0.        ],\n",
      "        [0.44541448, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6188829 , 0.        ],\n",
      "        [0.44628322, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6340768 , 0.        ],\n",
      "        [0.47014585, 0.        , 0.        , ..., 0.        ,\n",
      "         0.59377044, 0.        ],\n",
      "        [0.43162835, 0.        , 0.        , ..., 0.        ,\n",
      "         0.5969584 , 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.3828912 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6352991 , 0.        ],\n",
      "        [0.31711903, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7766813 , 0.        ],\n",
      "        [0.08383401, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8103727 , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.76671576, 0.        ],\n",
      "        [0.        , 0.        , 0.00231653, ..., 0.        ,\n",
      "         0.6918858 , 0.        ]],\n",
      "\n",
      "       [[1.2566323 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.93407595, 0.        ],\n",
      "        [1.2889824 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.86889195, 0.        ],\n",
      "        [1.1509466 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8932801 , 0.        ],\n",
      "        [1.0985086 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.83113337, 0.        ],\n",
      "        [1.0335987 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8246944 , 0.        ]],\n",
      "\n",
      "       [[1.2791448 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.77179855, 0.        ],\n",
      "        [1.2401804 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7843369 , 0.        ],\n",
      "        [1.2363381 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.81417066, 0.        ],\n",
      "        [1.3030844 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.84603953, 0.        ],\n",
      "        [1.2696351 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8654429 , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.42113352, 0.        , 0.06110731, ..., 0.        ,\n",
      "         0.9814338 , 0.        ],\n",
      "        [0.42366755, 0.        , 0.07825941, ..., 0.        ,\n",
      "         0.9700115 , 0.        ],\n",
      "        [0.42352164, 0.        , 0.06518707, ..., 0.        ,\n",
      "         1.0026186 , 0.        ],\n",
      "        [0.45345166, 0.        , 0.02681041, ..., 0.        ,\n",
      "         1.0139972 , 0.        ],\n",
      "        [0.44740534, 0.        , 0.05188739, ..., 0.        ,\n",
      "         0.9768002 , 0.        ]],\n",
      "\n",
      "       [[0.03865598, 0.        , 0.3241106 , ..., 0.        ,\n",
      "         0.5797809 , 0.        ],\n",
      "        [0.01714149, 0.        , 0.36099175, ..., 0.        ,\n",
      "         0.5665025 , 0.        ],\n",
      "        [0.04369691, 0.        , 0.3662646 , ..., 0.        ,\n",
      "         0.60237473, 0.        ],\n",
      "        [0.09990411, 0.        , 0.31139696, ..., 0.        ,\n",
      "         0.6115401 , 0.        ],\n",
      "        [0.07089964, 0.        , 0.34697288, ..., 0.        ,\n",
      "         0.5982308 , 0.        ]],\n",
      "\n",
      "       [[0.1337991 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.74860626, 0.        ],\n",
      "        [0.12951574, 0.        , 0.        , ..., 0.        ,\n",
      "         0.70279634, 0.        ],\n",
      "        [0.1367851 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.73263586, 0.        ],\n",
      "        [0.11380888, 0.        , 0.        , ..., 0.        ,\n",
      "         0.75954604, 0.        ],\n",
      "        [0.15960845, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6919943 , 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.2247964 , 0.        , 0.05200326, ..., 0.        ,\n",
      "         0.6585008 , 0.        ],\n",
      "        [1.1848052 , 0.        , 0.01943004, ..., 0.        ,\n",
      "         0.67242223, 0.        ],\n",
      "        [1.2696857 , 0.        , 0.03410798, ..., 0.        ,\n",
      "         0.6969026 , 0.        ],\n",
      "        [1.1799206 , 0.        , 0.03842682, ..., 0.        ,\n",
      "         0.61547667, 0.        ],\n",
      "        [1.2134271 , 0.        , 0.0427289 , ..., 0.        ,\n",
      "         0.6718233 , 0.        ]],\n",
      "\n",
      "       [[0.55415404, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6446342 , 0.        ],\n",
      "        [0.57754016, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6575871 , 0.        ],\n",
      "        [0.64379525, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6372081 , 0.        ],\n",
      "        [0.65459955, 0.        , 0.        , ..., 0.        ,\n",
      "         0.65560555, 0.        ],\n",
      "        [0.64850324, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6354551 , 0.        ]],\n",
      "\n",
      "       [[0.764098  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.70912015, 0.        ],\n",
      "        [0.82220984, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7426429 , 0.        ],\n",
      "        [0.81719345, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7061464 , 0.        ],\n",
      "        [0.7870893 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.70570385, 0.        ],\n",
      "        [0.7998442 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7039832 , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[1.1279736 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.69231445, 0.        ],\n",
      "        [1.1448092 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7041292 , 0.        ],\n",
      "        [1.1252666 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6834733 , 0.        ],\n",
      "        [1.1820405 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.65499187, 0.        ],\n",
      "        [1.0898815 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.672375  , 0.        ]],\n",
      "\n",
      "       [[1.3372811 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.81930304, 0.        ],\n",
      "        [1.2598516 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8597891 , 0.        ],\n",
      "        [1.2190952 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8782399 , 0.        ],\n",
      "        [1.1905206 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8825806 , 0.        ],\n",
      "        [1.1826073 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8548893 , 0.        ]],\n",
      "\n",
      "       [[0.11938021, 0.        , 0.05326679, ..., 0.        ,\n",
      "         1.0178919 , 0.        ],\n",
      "        [0.24247386, 0.        , 0.10086268, ..., 0.        ,\n",
      "         1.0433536 , 0.        ],\n",
      "        [0.17676078, 0.        , 0.08659172, ..., 0.        ,\n",
      "         1.0745028 , 0.        ],\n",
      "        [0.22342786, 0.        , 0.10267717, ..., 0.        ,\n",
      "         1.0388582 , 0.        ],\n",
      "        [0.12829629, 0.        , 0.07130536, ..., 0.        ,\n",
      "         1.0150459 , 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.3902695 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.43432778, 0.        ],\n",
      "        [1.308942  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.43928814, 0.        ],\n",
      "        [1.3939743 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.46431857, 0.        ],\n",
      "        [1.3353757 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.46618634, 0.        ],\n",
      "        [1.356682  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.4512591 , 0.        ]],\n",
      "\n",
      "       [[0.5408203 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7448484 , 0.        ],\n",
      "        [0.37870744, 0.        , 0.00167602, ..., 0.        ,\n",
      "         0.7645179 , 0.        ],\n",
      "        [0.20568764, 0.        , 0.08537522, ..., 0.        ,\n",
      "         0.7075147 , 0.        ],\n",
      "        [0.04695155, 0.        , 0.09433612, ..., 0.        ,\n",
      "         0.8055251 , 0.        ],\n",
      "        [0.01459771, 0.        , 0.08786595, ..., 0.        ,\n",
      "         0.7774992 , 0.        ]],\n",
      "\n",
      "       [[0.66594625, 0.        , 0.        , ..., 0.        ,\n",
      "         0.91414446, 0.        ],\n",
      "        [0.6964625 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9353025 , 0.        ],\n",
      "        [0.6520637 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.893891  , 0.        ],\n",
      "        [0.66520745, 0.        , 0.        , ..., 0.        ,\n",
      "         0.9079575 , 0.        ],\n",
      "        [0.7550694 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.93776584, 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[1.0277424 , 0.        , 0.05366865, ..., 0.        ,\n",
      "         0.8846147 , 0.        ],\n",
      "        [1.0712152 , 0.        , 0.04411128, ..., 0.        ,\n",
      "         0.9002343 , 0.        ],\n",
      "        [1.0559316 , 0.        , 0.02489054, ..., 0.        ,\n",
      "         0.9107814 , 0.        ],\n",
      "        [1.0625241 , 0.        , 0.03073734, ..., 0.        ,\n",
      "         0.91903   , 0.        ],\n",
      "        [1.0728413 , 0.        , 0.02792239, ..., 0.        ,\n",
      "         0.91976213, 0.        ]],\n",
      "\n",
      "       [[0.59532917, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8257154 , 0.        ],\n",
      "        [0.5405065 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8011988 , 0.        ],\n",
      "        [0.4890012 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7863413 , 0.        ],\n",
      "        [0.5242869 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7835826 , 0.        ],\n",
      "        [0.5087956 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.792302  , 0.        ]],\n",
      "\n",
      "       [[1.0769019 , 0.        , 0.33075255, ..., 0.        ,\n",
      "         0.9161557 , 0.        ],\n",
      "        [1.0505424 , 0.        , 0.32814136, ..., 0.        ,\n",
      "         0.88394266, 0.        ],\n",
      "        [1.0954227 , 0.        , 0.29268494, ..., 0.        ,\n",
      "         0.8972211 , 0.        ],\n",
      "        [1.0697696 , 0.        , 0.30091763, ..., 0.        ,\n",
      "         0.86728346, 0.        ],\n",
      "        [1.0759388 , 0.        , 0.31094608, ..., 0.        ,\n",
      "         0.88900834, 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.8055013 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.90895563, 0.        ],\n",
      "        [0.8424744 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9221417 , 0.        ],\n",
      "        [0.85207605, 0.        , 0.        , ..., 0.        ,\n",
      "         0.89752424, 0.        ],\n",
      "        [0.7807903 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8923663 , 0.        ],\n",
      "        [0.8450275 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9010358 , 0.        ]],\n",
      "\n",
      "       [[0.8771484 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.74147326, 0.        ],\n",
      "        [0.9356403 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7093543 , 0.        ],\n",
      "        [1.0305172 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.702296  , 0.        ],\n",
      "        [1.0224293 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.723626  , 0.        ],\n",
      "        [1.1227856 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7131272 , 0.        ]],\n",
      "\n",
      "       [[0.7902436 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7273691 , 0.        ],\n",
      "        [0.78231573, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7214593 , 0.        ],\n",
      "        [0.77156013, 0.        , 0.        , ..., 0.        ,\n",
      "         0.69359416, 0.        ],\n",
      "        [0.74131817, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6869616 , 0.        ],\n",
      "        [0.81875235, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6733926 , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.69759226, 0.        , 0.        , ..., 0.        ,\n",
      "         0.74061394, 0.        ],\n",
      "        [0.68758   , 0.        , 0.        , ..., 0.        ,\n",
      "         0.740537  , 0.        ],\n",
      "        [0.705651  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.77950287, 0.        ],\n",
      "        [0.71049684, 0.        , 0.        , ..., 0.        ,\n",
      "         0.76238704, 0.        ],\n",
      "        [0.695241  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7330232 , 0.        ]],\n",
      "\n",
      "       [[0.6053097 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6863625 , 0.        ],\n",
      "        [0.66166246, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6949298 , 0.        ],\n",
      "        [0.71200675, 0.        , 0.        , ..., 0.        ,\n",
      "         0.68879354, 0.        ],\n",
      "        [0.65434957, 0.        , 0.        , ..., 0.        ,\n",
      "         0.6978554 , 0.        ],\n",
      "        [0.6685278 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.66655827, 0.        ]],\n",
      "\n",
      "       [[0.6466124 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6170359 , 0.        ],\n",
      "        [0.5942146 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.58913976, 0.        ],\n",
      "        [0.61893207, 0.        , 0.        , ..., 0.        ,\n",
      "         0.5930963 , 0.        ],\n",
      "        [0.64690495, 0.        , 0.        , ..., 0.        ,\n",
      "         0.59035975, 0.        ],\n",
      "        [0.56472504, 0.        , 0.        , ..., 0.        ,\n",
      "         0.5942684 , 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.44173533, 0.        , 0.        , ..., 0.        ,\n",
      "         0.72870165, 0.        ],\n",
      "        [0.441538  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.712484  , 0.        ],\n",
      "        [0.41310355, 0.        , 0.        , ..., 0.        ,\n",
      "         0.71338516, 0.        ],\n",
      "        [0.45289156, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7200495 , 0.        ],\n",
      "        [0.436234  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.713266  , 0.        ]],\n",
      "\n",
      "       [[0.7640144 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8140175 , 0.        ],\n",
      "        [0.72203535, 0.        , 0.        , ..., 0.        ,\n",
      "         0.81354034, 0.        ],\n",
      "        [0.7427406 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.79073405, 0.        ],\n",
      "        [0.74871427, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8140086 , 0.        ],\n",
      "        [0.73523706, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7995615 , 0.        ]],\n",
      "\n",
      "       [[0.57184875, 0.        , 0.        , ..., 0.        ,\n",
      "         0.86479366, 0.        ],\n",
      "        [0.49947298, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8864687 , 0.        ],\n",
      "        [0.5428058 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.91338515, 0.        ],\n",
      "        [0.54091096, 0.        , 0.        , ..., 0.        ,\n",
      "         0.90704966, 0.        ],\n",
      "        [0.47985297, 0.        , 0.        , ..., 0.        ,\n",
      "         0.9012917 , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.9610756 , 0.        , 0.01015949, ..., 0.        ,\n",
      "         0.7507205 , 0.        ],\n",
      "        [0.9453278 , 0.        , 0.00379944, ..., 0.        ,\n",
      "         0.729408  , 0.        ],\n",
      "        [0.95826125, 0.        , 0.01102209, ..., 0.        ,\n",
      "         0.7285799 , 0.        ],\n",
      "        [0.95270324, 0.        , 0.01271808, ..., 0.        ,\n",
      "         0.7325086 , 0.        ],\n",
      "        [0.9720603 , 0.        , 0.01347941, ..., 0.        ,\n",
      "         0.7258076 , 0.        ]],\n",
      "\n",
      "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.44255382, 0.        ],\n",
      "        [0.02978632, 0.        , 0.        , ..., 0.        ,\n",
      "         0.43558532, 0.        ],\n",
      "        [0.02244674, 0.        , 0.        , ..., 0.        ,\n",
      "         0.46629888, 0.        ],\n",
      "        [0.10446387, 0.        , 0.        , ..., 0.        ,\n",
      "         0.49274004, 0.        ],\n",
      "        [0.17775078, 0.        , 0.        , ..., 0.        ,\n",
      "         0.51274306, 0.        ]],\n",
      "\n",
      "       [[0.35721505, 0.        , 0.08096543, ..., 0.        ,\n",
      "         0.70427835, 0.        ],\n",
      "        [0.32998213, 0.        , 0.0891957 , ..., 0.        ,\n",
      "         0.6817784 , 0.        ],\n",
      "        [0.26639256, 0.        , 0.1187045 , ..., 0.        ,\n",
      "         0.6953215 , 0.        ],\n",
      "        [0.25562656, 0.        , 0.09492821, ..., 0.        ,\n",
      "         0.68235195, 0.        ],\n",
      "        [0.23156211, 0.        , 0.1011197 , ..., 0.        ,\n",
      "         0.70536953, 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.43073058, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7608285 , 0.        ],\n",
      "        [0.40133524, 0.        , 0.        , ..., 0.        ,\n",
      "         0.76926625, 0.        ],\n",
      "        [0.46487698, 0.        , 0.        , ..., 0.        ,\n",
      "         0.73859817, 0.        ],\n",
      "        [0.42719126, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7375185 , 0.        ],\n",
      "        [0.4551352 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7515543 , 0.        ]],\n",
      "\n",
      "       [[0.3932647 , 0.        , 0.03908068, ..., 0.        ,\n",
      "         0.8016548 , 0.        ],\n",
      "        [0.39074263, 0.        , 0.04068017, ..., 0.        ,\n",
      "         0.7957347 , 0.        ],\n",
      "        [0.38151908, 0.        , 0.04189819, ..., 0.        ,\n",
      "         0.80304646, 0.        ],\n",
      "        [0.36303005, 0.        , 0.04237553, ..., 0.        ,\n",
      "         0.7923976 , 0.        ],\n",
      "        [0.31358612, 0.        , 0.03595072, ..., 0.        ,\n",
      "         0.7970785 , 0.        ]],\n",
      "\n",
      "       [[0.86048704, 0.        , 0.04005301, ..., 0.        ,\n",
      "         0.5498662 , 0.        ],\n",
      "        [0.8745798 , 0.        , 0.02773756, ..., 0.        ,\n",
      "         0.54706293, 0.        ],\n",
      "        [0.7814112 , 0.        , 0.04469284, ..., 0.        ,\n",
      "         0.5432881 , 0.        ],\n",
      "        [0.6495341 , 0.        , 0.10406727, ..., 0.        ,\n",
      "         0.4805175 , 0.        ],\n",
      "        [0.6579881 , 0.        , 0.10857335, ..., 0.        ,\n",
      "         0.48170882, 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.96918046, 0.        , 0.        , ..., 0.        ,\n",
      "         0.8060167 , 0.        ],\n",
      "        [0.96753925, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7732465 , 0.        ],\n",
      "        [0.94970983, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7554166 , 0.        ],\n",
      "        [0.9719778 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7617774 , 0.        ],\n",
      "        [0.97141105, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7496343 , 0.        ]],\n",
      "\n",
      "       [[0.6310796 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7589776 , 0.        ],\n",
      "        [0.6913622 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7880407 , 0.        ],\n",
      "        [0.7246902 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.78283155, 0.        ],\n",
      "        [0.76404023, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7562164 , 0.        ],\n",
      "        [0.76431644, 0.        , 0.        , ..., 0.        ,\n",
      "         0.76617014, 0.        ]],\n",
      "\n",
      "       [[0.8098559 , 0.        , 0.06410295, ..., 0.        ,\n",
      "         0.8960248 , 0.        ],\n",
      "        [0.8634184 , 0.        , 0.03755403, ..., 0.        ,\n",
      "         0.9089424 , 0.        ],\n",
      "        [0.8376013 , 0.        , 0.06048733, ..., 0.        ,\n",
      "         0.90170777, 0.        ],\n",
      "        [0.8613892 , 0.        , 0.05418471, ..., 0.        ,\n",
      "         0.8843941 , 0.        ],\n",
      "        [0.80948967, 0.        , 0.08161986, ..., 0.        ,\n",
      "         0.86636996, 0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.0908844 , 0.        , 0.2146773 , ..., 0.        ,\n",
      "         0.67270905, 0.        ],\n",
      "        [0.9393117 , 0.        , 0.2201277 , ..., 0.        ,\n",
      "         0.651902  , 0.        ],\n",
      "        [1.0806849 , 0.        , 0.23734248, ..., 0.        ,\n",
      "         0.63896275, 0.        ],\n",
      "        [1.0564551 , 0.        , 0.2903975 , ..., 0.        ,\n",
      "         0.67105556, 0.        ],\n",
      "        [1.0982106 , 0.        , 0.23367706, ..., 0.        ,\n",
      "         0.65311563, 0.        ]],\n",
      "\n",
      "       [[0.4360615 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.75856984, 0.        ],\n",
      "        [0.44084165, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7564627 , 0.        ],\n",
      "        [0.514006  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.75485253, 0.        ],\n",
      "        [0.46336895, 0.        , 0.        , ..., 0.        ,\n",
      "         0.76836014, 0.        ],\n",
      "        [0.5390028 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.77785826, 0.        ]],\n",
      "\n",
      "       [[0.85254836, 0.        , 0.        , ..., 0.        ,\n",
      "         0.74717236, 0.        ],\n",
      "        [0.75051445, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7399854 , 0.        ],\n",
      "        [0.7791788 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7337073 , 0.        ],\n",
      "        [0.6552739 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7281498 , 0.        ],\n",
      "        [0.77025735, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7361657 , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(16, 5, 4608), dtype=float32, numpy=\n",
      "array([[[2.3868248e-01, 0.0000000e+00, 8.7054253e-02, ...,\n",
      "         0.0000000e+00, 7.4131095e-01, 0.0000000e+00],\n",
      "        [2.4289021e-01, 0.0000000e+00, 9.3608677e-02, ...,\n",
      "         0.0000000e+00, 7.2412646e-01, 0.0000000e+00],\n",
      "        [2.2271492e-01, 0.0000000e+00, 9.0817004e-02, ...,\n",
      "         0.0000000e+00, 7.4281538e-01, 0.0000000e+00],\n",
      "        [2.4018031e-01, 0.0000000e+00, 9.2254817e-02, ...,\n",
      "         0.0000000e+00, 7.2457111e-01, 0.0000000e+00],\n",
      "        [2.4795155e-01, 0.0000000e+00, 1.3194096e-01, ...,\n",
      "         0.0000000e+00, 7.0294452e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[1.1555914e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.6296973e-01, 0.0000000e+00],\n",
      "        [1.1689694e+00, 0.0000000e+00, 1.1014342e-03, ...,\n",
      "         0.0000000e+00, 7.5640368e-01, 0.0000000e+00],\n",
      "        [1.1344445e+00, 0.0000000e+00, 1.1734366e-02, ...,\n",
      "         0.0000000e+00, 7.9160583e-01, 0.0000000e+00],\n",
      "        [1.1710863e+00, 0.0000000e+00, 1.2361646e-02, ...,\n",
      "         0.0000000e+00, 7.9086947e-01, 0.0000000e+00],\n",
      "        [1.1676266e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 7.7677429e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[8.3960330e-01, 0.0000000e+00, 6.9541633e-02, ...,\n",
      "         0.0000000e+00, 6.9138300e-01, 0.0000000e+00],\n",
      "        [8.7908345e-01, 0.0000000e+00, 5.1013857e-02, ...,\n",
      "         0.0000000e+00, 7.0534301e-01, 0.0000000e+00],\n",
      "        [9.0585208e-01, 0.0000000e+00, 2.2387922e-02, ...,\n",
      "         0.0000000e+00, 7.1302342e-01, 0.0000000e+00],\n",
      "        [8.8976377e-01, 0.0000000e+00, 3.5768330e-02, ...,\n",
      "         0.0000000e+00, 7.1757138e-01, 0.0000000e+00],\n",
      "        [8.3063990e-01, 0.0000000e+00, 6.7823917e-02, ...,\n",
      "         0.0000000e+00, 6.9958526e-01, 0.0000000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.4107294e+00, 0.0000000e+00, 1.6434687e-01, ...,\n",
      "         0.0000000e+00, 5.2810782e-01, 0.0000000e+00],\n",
      "        [1.4198388e+00, 0.0000000e+00, 1.2777576e-01, ...,\n",
      "         0.0000000e+00, 5.3026837e-01, 0.0000000e+00],\n",
      "        [1.4301066e+00, 0.0000000e+00, 1.5113798e-01, ...,\n",
      "         0.0000000e+00, 5.1743233e-01, 0.0000000e+00],\n",
      "        [1.4400775e+00, 0.0000000e+00, 1.4617214e-01, ...,\n",
      "         0.0000000e+00, 5.0691974e-01, 0.0000000e+00],\n",
      "        [1.3675429e+00, 0.0000000e+00, 1.3490438e-01, ...,\n",
      "         0.0000000e+00, 5.0243551e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[1.1383833e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 9.3346322e-01, 0.0000000e+00],\n",
      "        [1.1229415e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 8.9220607e-01, 0.0000000e+00],\n",
      "        [1.1566023e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 8.6889607e-01, 0.0000000e+00],\n",
      "        [1.1993852e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 8.9051008e-01, 0.0000000e+00],\n",
      "        [1.2828423e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 8.8766396e-01, 0.0000000e+00]],\n",
      "\n",
      "       [[1.4687635e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 5.2918935e-01, 0.0000000e+00],\n",
      "        [1.4697871e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 5.1377869e-01, 0.0000000e+00],\n",
      "        [1.5251306e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 5.2637869e-01, 0.0000000e+00],\n",
      "        [1.4414529e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 5.0338697e-01, 0.0000000e+00],\n",
      "        [1.4302322e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "         0.0000000e+00, 5.1901633e-01, 0.0000000e+00]]], dtype=float32)>, <tf.Tensor: shape=(16, 6), dtype=int32, numpy=\n",
      "array([[1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(6, 5, 4608), dtype=float32, numpy=\n",
      "array([[[0.41736138, 0.        , 0.        , ..., 0.        ,\n",
      "         0.81374633, 0.        ],\n",
      "        [0.38523585, 0.        , 0.        , ..., 0.        ,\n",
      "         0.7819469 , 0.        ],\n",
      "        [0.4114023 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7918186 , 0.        ],\n",
      "        [0.44167116, 0.        , 0.        , ..., 0.        ,\n",
      "         0.79122365, 0.        ],\n",
      "        [0.41778696, 0.        , 0.        , ..., 0.        ,\n",
      "         0.815633  , 0.        ]],\n",
      "\n",
      "       [[0.3060979 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8430332 , 0.        ],\n",
      "        [0.3321501 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.84639907, 0.        ],\n",
      "        [0.3045361 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.79965055, 0.        ],\n",
      "        [0.30376568, 0.        , 0.        , ..., 0.        ,\n",
      "         0.82595646, 0.        ],\n",
      "        [0.31164503, 0.        , 0.        , ..., 0.        ,\n",
      "         0.82155085, 0.        ]],\n",
      "\n",
      "       [[0.5157604 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8378643 , 0.        ],\n",
      "        [0.5062646 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.7743565 , 0.        ],\n",
      "        [0.4286337 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.8076257 , 0.        ],\n",
      "        [0.391501  , 0.        , 0.        , ..., 0.        ,\n",
      "         0.90400094, 0.        ],\n",
      "        [0.3350478 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.9049088 , 0.        ]],\n",
      "\n",
      "       [[1.3281513 , 0.        , 0.12232697, ..., 0.        ,\n",
      "         0.722201  , 0.        ],\n",
      "        [1.362574  , 0.        , 0.11345449, ..., 0.        ,\n",
      "         0.73367715, 0.        ],\n",
      "        [1.2795442 , 0.        , 0.12753752, ..., 0.        ,\n",
      "         0.72197545, 0.        ],\n",
      "        [1.2950509 , 0.        , 0.15466905, ..., 0.        ,\n",
      "         0.67938817, 0.        ],\n",
      "        [1.3098954 , 0.        , 0.14398521, ..., 0.        ,\n",
      "         0.6644332 , 0.        ]],\n",
      "\n",
      "       [[0.31551397, 0.        , 0.01064652, ..., 0.        ,\n",
      "         0.98722255, 0.        ],\n",
      "        [0.31913817, 0.        , 0.03604877, ..., 0.        ,\n",
      "         1.055837  , 0.        ],\n",
      "        [0.29079598, 0.        , 0.02967411, ..., 0.        ,\n",
      "         1.0532379 , 0.        ],\n",
      "        [0.31125772, 0.        , 0.02929884, ..., 0.        ,\n",
      "         1.0574124 , 0.        ],\n",
      "        [0.31272864, 0.        , 0.01617134, ..., 0.        ,\n",
      "         0.99763983, 0.        ]],\n",
      "\n",
      "       [[0.58578235, 0.        , 0.01183236, ..., 0.        ,\n",
      "         0.87093383, 0.        ],\n",
      "        [0.59481764, 0.        , 0.04799604, ..., 0.        ,\n",
      "         0.88475996, 0.        ],\n",
      "        [0.58670175, 0.        , 0.03118312, ..., 0.        ,\n",
      "         0.8728927 , 0.        ],\n",
      "        [0.5727204 , 0.        , 0.05125728, ..., 0.        ,\n",
      "         0.8787024 , 0.        ],\n",
      "        [0.55497134, 0.        , 0.01832783, ..., 0.        ,\n",
      "         0.8600826 , 0.        ]]], dtype=float32)>, <tf.Tensor: shape=(6, 6), dtype=int32, numpy=\n",
      "array([[0, 1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1],\n",
      "       [0, 1, 0, 0, 0, 0]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for x in test:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tf.keras.metrics.Precision(name=\"Precision\")\n",
    "recall = tf.keras.metrics.Recall(name=\"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "auc_metric = tf.keras.metrics.AUC(\n",
    "num_thresholds=200, curve=\"ROC\",\n",
    "summation_method=\"interpolation\",\n",
    "thresholds=None, multi_label=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_ccc_loss():\n",
    "        model = Sequential()\n",
    "        model.add(GRU(100, return_sequences=True, input_shape=[SEQUENCE_LENGTH, longest_feature]))\n",
    "        model.add(GRU(100, return_sequences=True))\n",
    "        model.add(GRU(50, return_sequences=False))\n",
    "        model.add(Dense(6))\n",
    "        # lr_schedule = ExponentialDecay(\n",
    "        #     initial_learning_rate=1e-2,\n",
    "        #     decay_steps=400,\n",
    "        #     decay_rate=0.97)\n",
    "        # opt = Adam(learning_rate=lr_schedule)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_rnn():\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(SEQUENCE_LENGTH, longest_feature)))\n",
    "    model.add(tf.keras.layers.GRU(512, dropout=0.5))\n",
    "    model.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\", precision, recall, custom_f1, auc_metric]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 12:49:14.101283: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16/Unknown - 6s 144ms/step - loss: 2.6720 - accuracy: 0.2602 - Precision: 0.2484 - Recall: 0.1043 - custom_f1: 0.1642 - auc_1: 0.5734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 12:49:20.264193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-19 12:49:22.362498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 12:49:22.364204: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 12:49:22.365605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 12:49:22.548976: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 12:49:22.550361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 12:49:22.551844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 12:49:22.575446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:22.586478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:22.769020: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 12:49:22.770467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 12:49:22.771809: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 12:49:22.962751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 12:49:22.964464: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 12:49:22.966162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 12:49:23.009488: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'masking_4_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node masking_4_input}}]]\n",
      "2023-04-19 12:49:23.031753: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'masking_4_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node masking_4_input}}]]\n",
      "2023-04-19 12:49:23.044259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:23.052507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:23.069311: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:23.078212: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:23.109401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'masking_4_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node masking_4_input}}]]\n",
      "2023-04-19 12:49:23.126649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:23.135806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:24.687031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 12:49:24.700384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 12:49:24.711022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:24.721999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 12:49:24.943554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 12:49:24.945956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 12:49:24.947944: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 12:49:25.112806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 12:49:25.114474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 12:49:25.115671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 12:49:25.319035: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 12:49:25.320522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 12:49:25.321723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 12:49:25.516153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 12:49:25.517680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 12:49:25.519016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_15_layer_call_fn, gru_cell_15_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
      "2023-04-19 12:49:25.670065: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_masking_4_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node serving_default_masking_4_input}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./chkpts/LSTM_Emotion_CK/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./chkpts/LSTM_Emotion_CK/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 13s 574ms/step - loss: 2.6720 - accuracy: 0.2602 - Precision: 0.2484 - Recall: 0.1043 - custom_f1: 0.1642 - auc_1: 0.5734 - val_loss: 2.0416 - val_accuracy: 0.1613 - val_Precision: 1.0000 - val_Recall: 0.0323 - val_custom_f1: 0.0588 - val_auc_1: 0.5643 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 1.9959 - accuracy: 0.2236 - Precision: 0.1579 - Recall: 0.0366 - custom_f1: 0.0476 - auc_1: 0.5904 - val_loss: 2.0175 - val_accuracy: 0.2581 - val_Precision: 0.1429 - val_Recall: 0.0323 - val_custom_f1: 0.0476 - val_auc_1: 0.5883 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.8561 - accuracy: 0.2073 - Precision: 0.3125 - Recall: 0.0203 - custom_f1: 0.0397 - auc_1: 0.5768 - val_loss: 1.8018 - val_accuracy: 0.2581 - val_Precision: 0.1429 - val_Recall: 0.0323 - val_custom_f1: 0.0526 - val_auc_1: 0.6279 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.7920 - accuracy: 0.2317 - Precision: 0.2143 - Recall: 0.0122 - custom_f1: 0.0186 - auc_1: 0.5958 - val_loss: 1.7261 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6410 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 1.7841 - accuracy: 0.1992 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.5888 - val_loss: 1.7116 - val_accuracy: 0.3226 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6260 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 1.7495 - accuracy: 0.2358 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6068 - val_loss: 1.7174 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6339 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.7568 - accuracy: 0.2114 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.5971 - val_loss: 1.7021 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6504 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.7451 - accuracy: 0.2317 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6084 - val_loss: 1.7050 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6325 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.7404 - accuracy: 0.2073 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6103 - val_loss: 1.7041 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6411 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 1.7355 - accuracy: 0.2520 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6135 - val_loss: 1.7007 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6461 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7316 - accuracy: 0.2520 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6178\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 1.7316 - accuracy: 0.2520 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6178 - val_loss: 1.7078 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6350 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 1.7247 - accuracy: 0.2398 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6251 - val_loss: 1.7034 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6412 - lr: 8.0000e-04\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.7282 - accuracy: 0.2642 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6196 - val_loss: 1.7013 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6491 - lr: 8.0000e-04\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.7321 - accuracy: 0.2602 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6207 - val_loss: 1.7058 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6347 - lr: 8.0000e-04\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.7264 - accuracy: 0.2642 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6221 - val_loss: 1.7070 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6452 - lr: 8.0000e-04\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 1.7358 - accuracy: 0.2439 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6151 - val_loss: 1.7054 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6442 - lr: 8.0000e-04\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.7241 - accuracy: 0.2561 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6233 - val_loss: 1.6992 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6485 - lr: 8.0000e-04\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7301 - accuracy: 0.2683 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6172\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 1.7301 - accuracy: 0.2683 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6172 - val_loss: 1.7050 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6390 - lr: 8.0000e-04\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 1.7167 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6291 - val_loss: 1.7040 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6481 - lr: 6.4000e-04\n",
      "Epoch 20/20\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 1.7272 - accuracy: 0.2386 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6206"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cnnrnn \u001b[39m=\u001b[39m keras_rnn()\n\u001b[0;32m----> 2\u001b[0m cnnrnn\u001b[39m.\u001b[39;49mfit(train_dataset, callbacks \u001b[39m=\u001b[39;49m callbacks, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalid_dataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnnrnn = keras_rnn()\n",
    "cnnrnn.fit(train_dataset, callbacks = callbacks, epochs=20, validation_data=valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout,Activation,BatchNormalization, Bidirectional, LSTM\n",
    "def LSTM_Biderectional():\n",
    "    regularizer = tf.keras.regularizers.l1_l2(0, 0.0001)\n",
    "    model = Sequential(name=\"Convolutional_Biderectional_LSTM\")\n",
    "\n",
    "    # model.add(tf.keras.layers.Masking(mask_value=0., input_shape=[SEQUENCE_LENGTH, longest_feature]))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.5)))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False, dropout = 0.4)))\n",
    "    model.add(Dense(512, kernel_regularizer=regularizer))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(rate=0.7))\n",
    "    model.add(Dense(units=6, activation=\"softmax\",kernel_regularizer=regularizer, kernel_initializer='he_normal')) \n",
    "    model.compile(optimizer='Nadam',\n",
    "                loss='categorical_crossentropy', metrics=[precision,recall,custom_f1, auc_metric,'accuracy'])\n",
    "\n",
    "    return model\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor = 'val_custom_f1',\n",
    "    factor=0.8,\n",
    "    patience=7,\n",
    "    min_lr = 1e-7,\n",
    "    verbose=1\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath='./chkpts/LSTM_Emotion_CK',monitor='val_custom_f1', mode='max',save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='max',patience=2)\n",
    "#The callbacks list now becomes:\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./clean_logs/Emotion/LSTM_Emotion_CK\")\n",
    "callbacks=[model_checkpoint_cb, lr_scheduler, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:19:00.265645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:00.267505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:00.268783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:00.455284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:00.531557: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:00.535386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:00.537076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:00.848622: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:00.850515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:00.851881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:01.061879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:01.145918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:01.148242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:01.150212: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:01.482218: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:01.484507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:01.486155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:01.702520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:01.780508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:01.782762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:01.784936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:02.091598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:02.094233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:02.096234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:02.264341: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:02.314339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:02.316469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:02.318378: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:02.801718: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:03.201553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:04.235203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:04.236871: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:04.238418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:04.386940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:04.437670: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:04.439807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:04.441467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:04.712862: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:04.714789: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:04.716072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:04.871766: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:04.921924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:04.923802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:04.925409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:05.412668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:05.820289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16/Unknown - 10s 121ms/step - loss: 1.8118 - Precision: 0.5455 - Recall: 0.0128 - custom_f1: 0.0375 - auc_1: 0.6054 - accuracy: 0.2236       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:19:10.667639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:10.669186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:10.670435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:10.860398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:10.937071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:10.939155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:10.941039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:11.183115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:11.185674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:11.187534: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:11.349860: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:11.409682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:11.412822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:11.414851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:12.386343: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:12.388278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:12.389709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:12.576604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:12.649441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:12.651894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:12.654664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:12.918136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:12.920296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:12.921540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:13.056201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:13.103230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:13.104510: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:13.105746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:13.325270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:13.326630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:13.328035: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:13.507987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:13.509423: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:13.510721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:13.537515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:13.548659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:13.692978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:13.735608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:13.737412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:13.739488: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:13.886055: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:13.932647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:13.934077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:13.935332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:13.965569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:13.976481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.162566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:14.164258: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:14.165503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:14.199812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.331056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:14.374842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:14.376120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:14.377551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:14.408358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.578003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:14.579610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:14.580985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:14.604616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.726804: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:14.771957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:14.773627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:14.775512: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:14.801269: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.815931: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.828217: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.837121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.845209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.854126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:14.862214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:15.050706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:15.052845: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:15.054478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:15.234258: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:15.235633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:15.237225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:15.265957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:15.275631: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:15.416470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:15.460913: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:15.462476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:15.464091: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:15.611516: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:15.657185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:15.658761: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:15.660018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:15.686560: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:15.696695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:15.879926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:15.881629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:15.882928: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:15.909350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.041117: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:16.086153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:16.088172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:16.089988: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:16.123264: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.287993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:16.291076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:16.292784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:16.320398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.442015: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:16.484826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:16.486048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:16.487470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:16.515160: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.531756: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.545315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.555225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.563838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.573523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.581966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:16.777923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:16.779977: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:16.781164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:16.925203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:16.969916: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:16.971304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:16.973592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:17.020280: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'bidirectional_32_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node bidirectional_32_input}}]]\n",
      "2023-04-19 13:19:17.195761: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:17.196998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:17.198073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:17.349756: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:17.395637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:17.397103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:17.398190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:17.642275: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:17.644219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:17.645895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:17.777721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:17.821058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:17.822440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:17.824025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:17.855213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'bidirectional_32_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node bidirectional_32_input}}]]\n",
      "2023-04-19 13:19:18.022040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:18.023618: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:18.024957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:18.167846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:18.214128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:18.215297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:18.216525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:18.276178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.317517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'bidirectional_32_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node bidirectional_32_input}}]]\n",
      "2023-04-19 13:19:18.332551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.370150: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'bidirectional_32_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node bidirectional_32_input}}]]\n",
      "2023-04-19 13:19:18.385077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.399101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.414765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.427505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.443106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.478258: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.499348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.556616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'bidirectional_32_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node bidirectional_32_input}}]]\n",
      "2023-04-19 13:19:18.596903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.620264: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:18.794503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:18.796181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:18.797422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:18.947639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:18.990258: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:18.991711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:18.992789: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:19.185823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:19.187374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:19.188960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:19.333583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:19.378367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:19.379792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:19.380903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:19.596135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:19.598032: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:19.599187: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:19.728693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:19.771389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:19.772981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:19.774635: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:19.958848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:19.960636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:19.962471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:20.092520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:20.138736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:20.140522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:20.141916: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:20.202350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:20.216580: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:20.230052: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:20.241890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:20.414981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:20.416691: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:20.417922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:20.566994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:20.610757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:20.612408: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:20.613679: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:20.800763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:20.802429: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:20.803954: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:20.933452: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:21.008176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:21.010741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:21.012965: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:21.257349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:21.259086: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:21.260282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:21.402560: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:21.448118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:21.449350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:21.450493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:21.643209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:21.645487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:21.646887: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:21.823513: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:21.886025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:21.887706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:21.889054: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:21.938043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:21.949989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:21.962084: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:21.973368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:22.153259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:22.155077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:22.156339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:22.298868: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:22.344465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:22.346191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:22.347375: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:22.538577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:22.540872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:22.542444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:22.670998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:22.714974: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:22.716183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:22.717596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:22.915880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:22.918047: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:22.919671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:23.061948: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:23.105815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:23.107492: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:23.108733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:23.297212: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:23.299062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:23.300437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:23.429080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:23.472579: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:23.474226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:23.475581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:23.538928: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:23.600207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:23.608305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:23.616506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:23.624301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:23.799272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:23.800858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:23.801989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:23.977575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:23.979013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:23.980288: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:24.173753: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:24.175670: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:24.177305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:24.349558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:24.350966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:24.352250: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:24.390704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:24.400504: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,4608]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:24.412503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:24.421024: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:24.552786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:24.598582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:24.600131: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:24.601312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:24.762702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:24.806170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:24.807989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:24.809128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:24.964971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:25.009530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:25.011232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:25.012330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:25.155712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:25.198573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:25.199890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:25.201105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:25.242684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,256]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:25.254721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,256]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:25.263926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:25.272336: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:25.441509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:25.443285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:25.445974: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:25.631482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:25.632870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:25.634406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:25.835314: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:25.837506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:25.839314: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:26.016583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:26.017877: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:26.019006: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:26.059645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,256]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:26.070654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,256]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-19 13:19:26.080619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:26.089513: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-19 13:19:28.220178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:28.285551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:28.287236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:28.289079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:28.520324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:28.587594: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:28.590524: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:28.592510: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:28.844330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:28.900212: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:28.902425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:28.904567: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:19:29.096274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:19:29.162128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:19:29.164229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:19:29.166044: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_83_layer_call_fn, lstm_cell_83_layer_call_and_return_conditional_losses, lstm_cell_84_layer_call_fn, lstm_cell_84_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n",
      "2023-04-19 13:19:29.511159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_bidirectional_32_input' with dtype float and shape [?,5,4608]\n",
      "\t [[{{node serving_default_bidirectional_32_input}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./chkpts/LSTM_Emotion_CK/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./chkpts/LSTM_Emotion_CK/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 32s 2s/step - loss: 1.8118 - Precision: 0.5455 - Recall: 0.0128 - custom_f1: 0.0375 - auc_1: 0.6054 - accuracy: 0.2236 - val_loss: 1.7347 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6495 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 1.8080 - Precision: 0.3750 - Recall: 0.0122 - custom_f1: 0.0199 - auc_1: 0.6023 - accuracy: 0.2195 - val_loss: 1.7951 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.5928 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 1.8308 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.5808 - accuracy: 0.2033 - val_loss: 1.7429 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6367 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 1.8111 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.5888 - accuracy: 0.2439 - val_loss: 1.7435 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6417 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 1.8041 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.5953 - accuracy: 0.2114 - val_loss: 1.7315 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6395 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 1.7618 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6177 - accuracy: 0.2520 - val_loss: 1.7396 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6117 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 1.7712 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6127 - accuracy: 0.2195 - val_loss: 1.7246 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6451 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7525 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6250 - accuracy: 0.2398\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 1.7525 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6250 - accuracy: 0.2398 - val_loss: 1.7307 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6362 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 1.7618 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6206 - accuracy: 0.2561 - val_loss: 1.7221 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6395 - val_accuracy: 0.2581 - lr: 8.0000e-04\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 1.7788 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6027 - accuracy: 0.2561 - val_loss: 1.7285 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6400 - val_accuracy: 0.2581 - lr: 8.0000e-04\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 1.7578 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6161 - accuracy: 0.2480 - val_loss: 1.7293 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6348 - val_accuracy: 0.2581 - lr: 8.0000e-04\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 1.7306 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6370 - accuracy: 0.2439 - val_loss: 1.7311 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6294 - val_accuracy: 0.2581 - lr: 8.0000e-04\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 1.7586 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6160 - accuracy: 0.2561 - val_loss: 1.7302 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6333 - val_accuracy: 0.2581 - lr: 8.0000e-04\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 1.7516 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6182 - accuracy: 0.2480 - val_loss: 1.7249 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6392 - val_accuracy: 0.2581 - lr: 8.0000e-04\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7504 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6217 - accuracy: 0.2480\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 1.7504 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6217 - accuracy: 0.2480 - val_loss: 1.7239 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6411 - val_accuracy: 0.2581 - lr: 8.0000e-04\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 1.7522 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6238 - accuracy: 0.2764 - val_loss: 1.7222 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_custom_f1: 0.0000e+00 - val_auc_1: 0.6406 - val_accuracy: 0.2581 - lr: 6.4000e-04\n",
      "Epoch 17/100\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 1.7434 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - custom_f1: 0.0000e+00 - auc_1: 0.6247 - accuracy: 0.2216"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cnnrnn \u001b[39m=\u001b[39m LSTM_Biderectional()\n\u001b[0;32m----> 2\u001b[0m cnnrnn\u001b[39m.\u001b[39;49mfit(train_dataset, callbacks \u001b[39m=\u001b[39;49m callbacks, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalid_dataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnnrnn = LSTM_Biderectional()\n",
    "cnnrnn.fit(train_dataset, callbacks = callbacks, epochs=100, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM\n",
    "def gru_ccc_loss():\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(256, return_sequences=True, input_shape=[SEQUENCE_LENGTH, longest_feature], dropout=0.5)))\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=False, dropout=0.5, recurrent_dropout=0.5)))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(6, activation='softmax'))\n",
    "        lr_schedule = ExponentialDecay(\n",
    "             initial_learning_rate=1e-2,\n",
    "             decay_steps=400,\n",
    "             decay_rate=0.97)\n",
    "        opt = Adam(learning_rate=lr_schedule)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=opt,\n",
    "                      metrics=['accuracy', precision, recall])\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \nCall to cuInit results in CUDA_ERROR_UNKNOWN (999):",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumba\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda\n\u001b[0;32m----> 2\u001b[0m device \u001b[39m=\u001b[39m cuda\u001b[39m.\u001b[39;49mget_current_device()\n\u001b[1;32m      3\u001b[0m device\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/numba/cuda/api.py:435\u001b[0m, in \u001b[0;36mget_current_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_current_device\u001b[39m():\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mGet current device associated with the current thread\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 435\u001b[0m     \u001b[39mreturn\u001b[39;00m current_context()\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py:220\u001b[0m, in \u001b[0;36mget_context\u001b[0;34m(devnum)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_context\u001b[39m(devnum\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    217\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the current device or use a device by device number, and\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m    return the CUDA context.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     \u001b[39mreturn\u001b[39;00m _runtime\u001b[39m.\u001b[39;49mget_or_create_context(devnum)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py:138\u001b[0m, in \u001b[0;36m_Runtime.get_or_create_context\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m    136\u001b[0m attached_ctx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_attached_context()\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m attached_ctx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_or_create_context_uncached(devnum)\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m attached_ctx\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py:153\u001b[0m, in \u001b[0;36m_Runtime._get_or_create_context_uncached\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"See also ``get_or_create_context(devnum)``.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39mThis version does not read the cache.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    151\u001b[0m     \u001b[39m# Try to get the active context in the CUDA stack or\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[39m# activate GPU-0 with the primary context\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mwith\u001b[39;00m driver\u001b[39m.\u001b[39mget_active_context() \u001b[39mas\u001b[39;00m ac:\n\u001b[1;32m    154\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ac:\n\u001b[1;32m    155\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activate_context_for(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py:488\u001b[0m, in \u001b[0;36m_ActiveContext.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     hctx \u001b[39m=\u001b[39m drvapi\u001b[39m.\u001b[39mcu_context(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 488\u001b[0m     driver\u001b[39m.\u001b[39;49mcuCtxGetCurrent(byref(hctx))\n\u001b[1;32m    489\u001b[0m     hctx \u001b[39m=\u001b[39m hctx \u001b[39mif\u001b[39;00m hctx\u001b[39m.\u001b[39mvalue \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m hctx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py:288\u001b[0m, in \u001b[0;36mDriver.__getattr__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialization_error \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mraise\u001b[39;00m CudaSupportError(\u001b[39m\"\u001b[39m\u001b[39mError at driver init: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    289\u001b[0m                            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialization_error)\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m USE_NV_BINDING:\n\u001b[1;32m    292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cuda_python_wrap_fn(fname)\n",
      "\u001b[0;31mCudaSupportError\u001b[0m: Error at driver init: \nCall to cuInit results in CUDA_ERROR_UNKNOWN (999):"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:26:10.975591: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:26:10.978422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:26:10.980579: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:26:11.186901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:26:11.258824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:26:11.260595: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:26:11.262960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:26:11.938548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:26:11.941156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:26:11.942900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:26:12.100783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:26:12.150965: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:26:12.154145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:26:12.155814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:26:13.996811: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:26:15.032675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:26:15.034800: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:26:15.036404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:26:15.194224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:26:15.252301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:26:15.255350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:26:15.257360: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:26:16.928472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16/Unknown - 12s 195ms/step - loss: 1.9192 - accuracy: 0.2195 - Precision: 0.1351 - Recall: 0.0128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:26:22.995776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:26:22.997598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:26:22.998771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 13:26:23.134222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-19 13:26:23.180465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 13:26:23.181863: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 13:26:23.183403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 13s 272ms/step - loss: 1.9192 - accuracy: 0.2195 - Precision: 0.1351 - Recall: 0.0128 - val_loss: 1.7411 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 1.7979 - accuracy: 0.1951 - Precision: 0.5000 - Recall: 0.0041 - val_loss: 1.7184 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 1.7449 - accuracy: 0.2602 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7096 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.7244 - accuracy: 0.2154 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7085 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.7227 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7055 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 1.7433 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7183 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 1.7162 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7020 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 1.7192 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7036 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 1.7257 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7067 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.7126 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7052 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.7110 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7097 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 1.7195 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7094 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 1.7145 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7075 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 1.7128 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7059 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.7075 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7047 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 1.7066 - accuracy: 0.2724 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.7041 - val_accuracy: 0.2581 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 17/100\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 1.7053 - accuracy: 0.2596 - Precision: 0.0000e+00 - Recall: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m gru_ccc_loss()\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalid_dataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = gru_ccc_loss()\n",
    "model.fit(train_dataset, epochs=100, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Masking(mask_value=0.),\n",
    "tf.keras.layers.LSTM(1024, dropout=0.5, recurrent_dropout=0.5, return_sequences=True),\n",
    "tf.keras.layers.LSTM(512, return_sequences=False),\n",
    "Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy', precision, recall])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 12:32:56.086445: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 36.00MiB (rounded to 37748736)requested by op sequential_12/lstm_10/while/body/_1/sequential_12/lstm_10/while/lstm_cell_10/split\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-04-17 12:32:56.086495: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-04-17 12:32:56.086509: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 220, Chunks in use: 219. 55.0KiB allocated for chunks. 54.8KiB in use in bin. 1.6KiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086546: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086557: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086567: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 9, Chunks in use: 9. 23.5KiB allocated for chunks. 23.5KiB in use in bin. 21.0KiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086577: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 12, Chunks in use: 12. 54.2KiB allocated for chunks. 54.2KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086587: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 5, Chunks in use: 5. 55.5KiB allocated for chunks. 55.5KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086596: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 72, Chunks in use: 71. 1.24MiB allocated for chunks. 1.21MiB in use in bin. 1.11MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086606: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 40.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086614: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086623: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 35, Chunks in use: 35. 5.36MiB allocated for chunks. 5.36MiB in use in bin. 4.92MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086632: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 7, Chunks in use: 7. 2.09MiB allocated for chunks. 2.09MiB in use in bin. 1.42MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086642: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 5, Chunks in use: 4. 3.21MiB allocated for chunks. 2.51MiB in use in bin. 2.00MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086651: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 4, Chunks in use: 4. 5.21MiB allocated for chunks. 5.21MiB in use in bin. 4.00MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086660: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 0. 3.25MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086670: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 31, Chunks in use: 31. 127.38MiB allocated for chunks. 127.38MiB in use in bin. 124.00MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086680: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 3, Chunks in use: 3. 24.00MiB allocated for chunks. 24.00MiB in use in bin. 24.00MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086690: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 4, Chunks in use: 4. 84.40MiB allocated for chunks. 84.40MiB in use in bin. 64.00MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086699: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 31, Chunks in use: 31. 1.18GiB allocated for chunks. 1.18GiB in use in bin. 1.09GiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086709: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 2, Chunks in use: 2. 141.99MiB allocated for chunks. 141.99MiB in use in bin. 72.00MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086720: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 4. 689.25MiB allocated for chunks. 689.25MiB in use in bin. 576.00MiB client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086729: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 12:32:56.086738: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 36.00MiB was 32.00MiB, Chunk State: \n",
      "2023-04-17 12:32:56.086746: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2411462656\n",
      "2023-04-17 12:32:56.086758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800000 of size 1280 next 1\n",
      "2023-04-17 12:32:56.086766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800500 of size 256 next 2\n",
      "2023-04-17 12:32:56.086773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800600 of size 256 next 3\n",
      "2023-04-17 12:32:56.086781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800700 of size 256 next 4\n",
      "2023-04-17 12:32:56.086788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800800 of size 256 next 5\n",
      "2023-04-17 12:32:56.086796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800900 of size 256 next 154\n",
      "2023-04-17 12:32:56.086803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800a00 of size 256 next 321\n",
      "2023-04-17 12:32:56.086811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800b00 of size 256 next 602\n",
      "2023-04-17 12:32:56.086818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800c00 of size 256 next 9\n",
      "2023-04-17 12:32:56.086825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800d00 of size 256 next 10\n",
      "2023-04-17 12:32:56.086833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800e00 of size 256 next 11\n",
      "2023-04-17 12:32:56.086840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603800f00 of size 256 next 12\n",
      "2023-04-17 12:32:56.086847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801000 of size 256 next 13\n",
      "2023-04-17 12:32:56.086855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801100 of size 256 next 14\n",
      "2023-04-17 12:32:56.086862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801200 of size 256 next 15\n",
      "2023-04-17 12:32:56.086872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801300 of size 256 next 16\n",
      "2023-04-17 12:32:56.086880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801400 of size 256 next 18\n",
      "2023-04-17 12:32:56.086887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801500 of size 256 next 19\n",
      "2023-04-17 12:32:56.086895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801600 of size 256 next 20\n",
      "2023-04-17 12:32:56.086902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801700 of size 256 next 28\n",
      "2023-04-17 12:32:56.086909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801800 of size 256 next 35\n",
      "2023-04-17 12:32:56.086917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801900 of size 256 next 31\n",
      "2023-04-17 12:32:56.086924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801a00 of size 256 next 37\n",
      "2023-04-17 12:32:56.086932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801b00 of size 256 next 41\n",
      "2023-04-17 12:32:56.086939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801c00 of size 256 next 43\n",
      "2023-04-17 12:32:56.086947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801d00 of size 256 next 23\n",
      "2023-04-17 12:32:56.086954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801e00 of size 256 next 17\n",
      "2023-04-17 12:32:56.086962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603801f00 of size 2560 next 450\n",
      "2023-04-17 12:32:56.086971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603802900 of size 256 next 509\n",
      "2023-04-17 12:32:56.086979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603802a00 of size 256 next 237\n",
      "2023-04-17 12:32:56.086986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603802b00 of size 256 next 609\n",
      "2023-04-17 12:32:56.086994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603802c00 of size 256 next 688\n",
      "2023-04-17 12:32:56.087001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603802d00 of size 256 next 116\n",
      "2023-04-17 12:32:56.087009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603802e00 of size 256 next 261\n",
      "2023-04-17 12:32:56.087017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603802f00 of size 256 next 683\n",
      "2023-04-17 12:32:56.087024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603803000 of size 4096 next 532\n",
      "2023-04-17 12:32:56.087035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603804000 of size 2048 next 29\n",
      "2023-04-17 12:32:56.087043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603804800 of size 2048 next 137\n",
      "2023-04-17 12:32:56.087051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805000 of size 2048 next 634\n",
      "2023-04-17 12:32:56.087058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805800 of size 256 next 639\n",
      "2023-04-17 12:32:56.087066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805900 of size 256 next 90\n",
      "2023-04-17 12:32:56.087073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805a00 of size 256 next 739\n",
      "2023-04-17 12:32:56.087081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805b00 of size 256 next 508\n",
      "2023-04-17 12:32:56.087089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805c00 of size 256 next 392\n",
      "2023-04-17 12:32:56.087096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805d00 of size 256 next 771\n",
      "2023-04-17 12:32:56.087104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805e00 of size 256 next 67\n",
      "2023-04-17 12:32:56.087111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603805f00 of size 256 next 155\n",
      "2023-04-17 12:32:56.087119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603806000 of size 256 next 279\n",
      "2023-04-17 12:32:56.087126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603806100 of size 256 next 140\n",
      "2023-04-17 12:32:56.087134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603806200 of size 256 next 84\n",
      "2023-04-17 12:32:56.087142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603806300 of size 256 next 744\n",
      "2023-04-17 12:32:56.087149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603806400 of size 4864 next 559\n",
      "2023-04-17 12:32:56.087158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603807700 of size 256 next 534\n",
      "2023-04-17 12:32:56.087165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603807800 of size 256 next 512\n",
      "2023-04-17 12:32:56.087173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603807900 of size 25856 next 341\n",
      "2023-04-17 12:32:56.087180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60380de00 of size 256 next 223\n",
      "2023-04-17 12:32:56.087188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60380df00 of size 256 next 353\n",
      "2023-04-17 12:32:56.087195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60380e000 of size 256 next 447\n",
      "2023-04-17 12:32:56.087203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60380e100 of size 256 next 209\n",
      "2023-04-17 12:32:56.087211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60380e200 of size 16384 next 710\n",
      "2023-04-17 12:32:56.087219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603812200 of size 12288 next 776\n",
      "2023-04-17 12:32:56.087227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603815200 of size 12544 next 87\n",
      "2023-04-17 12:32:56.087235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603818300 of size 256 next 95\n",
      "2023-04-17 12:32:56.087244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603818400 of size 4096 next 564\n",
      "2023-04-17 12:32:56.087252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603819400 of size 4096 next 471\n",
      "2023-04-17 12:32:56.087260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381a400 of size 256 next 386\n",
      "2023-04-17 12:32:56.087267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381a500 of size 256 next 206\n",
      "2023-04-17 12:32:56.087275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381a600 of size 256 next 607\n",
      "2023-04-17 12:32:56.087282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381a700 of size 256 next 510\n",
      "2023-04-17 12:32:56.087291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381a800 of size 256 next 748\n",
      "2023-04-17 12:32:56.087298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381a900 of size 256 next 597\n",
      "2023-04-17 12:32:56.087306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381aa00 of size 5632 next 354\n",
      "2023-04-17 12:32:56.087314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c000 of size 256 next 670\n",
      "2023-04-17 12:32:56.087321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c100 of size 256 next 345\n",
      "2023-04-17 12:32:56.087330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c200 of size 256 next 373\n",
      "2023-04-17 12:32:56.087338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c300 of size 256 next 102\n",
      "2023-04-17 12:32:56.087346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c400 of size 256 next 48\n",
      "2023-04-17 12:32:56.087353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c500 of size 256 next 517\n",
      "2023-04-17 12:32:56.087361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c600 of size 256 next 135\n",
      "2023-04-17 12:32:56.087369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c700 of size 256 next 542\n",
      "2023-04-17 12:32:56.087376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c800 of size 256 next 117\n",
      "2023-04-17 12:32:56.087385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381c900 of size 256 next 101\n",
      "2023-04-17 12:32:56.087393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381ca00 of size 256 next 401\n",
      "2023-04-17 12:32:56.087401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381cb00 of size 256 next 324\n",
      "2023-04-17 12:32:56.087408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381cc00 of size 256 next 213\n",
      "2023-04-17 12:32:56.087416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381cd00 of size 256 next 333\n",
      "2023-04-17 12:32:56.087423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381ce00 of size 256 next 125\n",
      "2023-04-17 12:32:56.087431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381cf00 of size 256 next 507\n",
      "2023-04-17 12:32:56.087439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d000 of size 256 next 399\n",
      "2023-04-17 12:32:56.087446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d100 of size 256 next 436\n",
      "2023-04-17 12:32:56.087454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d200 of size 256 next 388\n",
      "2023-04-17 12:32:56.087461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d300 of size 256 next 562\n",
      "2023-04-17 12:32:56.087469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d400 of size 256 next 494\n",
      "2023-04-17 12:32:56.087476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d500 of size 256 next 250\n",
      "2023-04-17 12:32:56.087484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d600 of size 256 next 714\n",
      "2023-04-17 12:32:56.087492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d700 of size 256 next 149\n",
      "2023-04-17 12:32:56.087500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d800 of size 256 next 267\n",
      "2023-04-17 12:32:56.087507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381d900 of size 256 next 81\n",
      "2023-04-17 12:32:56.087515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381da00 of size 256 next 317\n",
      "2023-04-17 12:32:56.087530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381db00 of size 256 next 383\n",
      "2023-04-17 12:32:56.087543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381dc00 of size 256 next 33\n",
      "2023-04-17 12:32:56.087554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381dd00 of size 256 next 613\n",
      "2023-04-17 12:32:56.087565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381de00 of size 256 next 236\n",
      "2023-04-17 12:32:56.087577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381df00 of size 256 next 745\n",
      "2023-04-17 12:32:56.087592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381e000 of size 256 next 674\n",
      "2023-04-17 12:32:56.087604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381e100 of size 256 next 289\n",
      "2023-04-17 12:32:56.087619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381e200 of size 3072 next 690\n",
      "2023-04-17 12:32:56.087635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381ee00 of size 3072 next 24\n",
      "2023-04-17 12:32:56.087650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381fa00 of size 256 next 189\n",
      "2023-04-17 12:32:56.087659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60381fb00 of size 2048 next 111\n",
      "2023-04-17 12:32:56.087667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820300 of size 256 next 365\n",
      "2023-04-17 12:32:56.087675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820400 of size 256 next 193\n",
      "2023-04-17 12:32:56.087682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820500 of size 256 next 774\n",
      "2023-04-17 12:32:56.087689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820600 of size 256 next 617\n",
      "2023-04-17 12:32:56.087697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820700 of size 256 next 257\n",
      "2023-04-17 12:32:56.087704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820800 of size 256 next 266\n",
      "2023-04-17 12:32:56.087712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820900 of size 256 next 631\n",
      "2023-04-17 12:32:56.087719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820a00 of size 256 next 698\n",
      "2023-04-17 12:32:56.087727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820b00 of size 256 next 194\n",
      "2023-04-17 12:32:56.087735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820c00 of size 256 next 79\n",
      "2023-04-17 12:32:56.087742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820d00 of size 256 next 428\n",
      "2023-04-17 12:32:56.087749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820e00 of size 256 next 320\n",
      "2023-04-17 12:32:56.087757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603820f00 of size 256 next 466\n",
      "2023-04-17 12:32:56.087764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821000 of size 256 next 184\n",
      "2023-04-17 12:32:56.087772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821100 of size 256 next 591\n",
      "2023-04-17 12:32:56.087780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821200 of size 256 next 630\n",
      "2023-04-17 12:32:56.087787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821300 of size 256 next 788\n",
      "2023-04-17 12:32:56.087794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821400 of size 256 next 612\n",
      "2023-04-17 12:32:56.087802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821500 of size 256 next 100\n",
      "2023-04-17 12:32:56.087809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821600 of size 256 next 606\n",
      "2023-04-17 12:32:56.087817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821700 of size 256 next 483\n",
      "2023-04-17 12:32:56.087824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603821800 of size 4096 next 459\n",
      "2023-04-17 12:32:56.087833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603822800 of size 6144 next 201\n",
      "2023-04-17 12:32:56.087840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603824000 of size 8192 next 651\n",
      "2023-04-17 12:32:56.087848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603826000 of size 22784 next 378\n",
      "2023-04-17 12:32:56.087856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60382b900 of size 256 next 336\n",
      "2023-04-17 12:32:56.087864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60382ba00 of size 18688 next 166\n",
      "2023-04-17 12:32:56.087872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603830300 of size 256 next 247\n",
      "2023-04-17 12:32:56.087879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603830400 of size 11520 next 455\n",
      "2023-04-17 12:32:56.087887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603833100 of size 256 next 325\n",
      "2023-04-17 12:32:56.087894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603833200 of size 394752 next 658\n",
      "2023-04-17 12:32:56.087903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 603893800 of size 262144 next 32\n",
      "2023-04-17 12:32:56.087910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 6038d3800 of size 32178176 next 30\n",
      "2023-04-17 12:32:56.087918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 605783800 of size 56623104 next 364\n",
      "2023-04-17 12:32:56.087926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 608d83800 of size 75136768 next 312\n",
      "2023-04-17 12:32:56.087934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d52b700 of size 256 next 138\n",
      "2023-04-17 12:32:56.087942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d52b800 of size 256 next 712\n",
      "2023-04-17 12:32:56.087950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d52b900 of size 1309952 next 635\n",
      "2023-04-17 12:32:56.087958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66b600 of size 256 next 372\n",
      "2023-04-17 12:32:56.087965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66b700 of size 256 next 396\n",
      "2023-04-17 12:32:56.087973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66b800 of size 256 next 767\n",
      "2023-04-17 12:32:56.087980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66b900 of size 256 next 152\n",
      "2023-04-17 12:32:56.087987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66ba00 of size 256 next 34\n",
      "2023-04-17 12:32:56.087995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66bb00 of size 256 next 439\n",
      "2023-04-17 12:32:56.088002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66bc00 of size 256 next 493\n",
      "2023-04-17 12:32:56.088010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66bd00 of size 256 next 74\n",
      "2023-04-17 12:32:56.088017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66be00 of size 256 next 347\n",
      "2023-04-17 12:32:56.088024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66bf00 of size 256 next 114\n",
      "2023-04-17 12:32:56.088032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c000 of size 256 next 524\n",
      "2023-04-17 12:32:56.088039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c100 of size 256 next 314\n",
      "2023-04-17 12:32:56.088047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c200 of size 256 next 208\n",
      "2023-04-17 12:32:56.088054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c300 of size 256 next 240\n",
      "2023-04-17 12:32:56.088062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c400 of size 256 next 382\n",
      "2023-04-17 12:32:56.088070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c500 of size 256 next 654\n",
      "2023-04-17 12:32:56.088077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c600 of size 256 next 584\n",
      "2023-04-17 12:32:56.088085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c700 of size 256 next 693\n",
      "2023-04-17 12:32:56.088092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c800 of size 256 next 655\n",
      "2023-04-17 12:32:56.088100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d66c900 of size 20480 next 565\n",
      "2023-04-17 12:32:56.088108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d671900 of size 256 next 669\n",
      "2023-04-17 12:32:56.088116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d671a00 of size 12288 next 297\n",
      "2023-04-17 12:32:56.088123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d674a00 of size 22528 next 764\n",
      "2023-04-17 12:32:56.088131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67a200 of size 256 next 344\n",
      "2023-04-17 12:32:56.088138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67a300 of size 256 next 109\n",
      "2023-04-17 12:32:56.088145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67a400 of size 256 next 210\n",
      "2023-04-17 12:32:56.088153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67a500 of size 256 next 350\n",
      "2023-04-17 12:32:56.088161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67a600 of size 256 next 551\n",
      "2023-04-17 12:32:56.088168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67a700 of size 256 next 416\n",
      "2023-04-17 12:32:56.088176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67a800 of size 256 next 575\n",
      "2023-04-17 12:32:56.088183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67a900 of size 256 next 555\n",
      "2023-04-17 12:32:56.088191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67aa00 of size 256 next 461\n",
      "2023-04-17 12:32:56.088198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67ab00 of size 256 next 110\n",
      "2023-04-17 12:32:56.088206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67ac00 of size 256 next 432\n",
      "2023-04-17 12:32:56.088213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67ad00 of size 256 next 290\n",
      "2023-04-17 12:32:56.088222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67ae00 of size 256 next 381\n",
      "2023-04-17 12:32:56.088231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67af00 of size 256 next 645\n",
      "2023-04-17 12:32:56.088238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67b000 of size 256 next 181\n",
      "2023-04-17 12:32:56.088246: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67b100 of size 256 next 387\n",
      "2023-04-17 12:32:56.088253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67b200 of size 256 next 272\n",
      "2023-04-17 12:32:56.088261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67b300 of size 256 next 233\n",
      "2023-04-17 12:32:56.088268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67b400 of size 256 next 98\n",
      "2023-04-17 12:32:56.088276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67b500 of size 256 next 724\n",
      "2023-04-17 12:32:56.088283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67b600 of size 256 next 112\n",
      "2023-04-17 12:32:56.088291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 60d67b700 of size 59622912 next 550\n",
      "2023-04-17 12:32:56.088299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 610f57d00 of size 163494400 next 86\n",
      "2023-04-17 12:32:56.088308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ab43700 of size 147456 next 282\n",
      "2023-04-17 12:32:56.088317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ab67700 of size 147456 next 366\n",
      "2023-04-17 12:32:56.088325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ab8b700 of size 147456 next 583\n",
      "2023-04-17 12:32:56.088333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61abaf700 of size 147456 next 516\n",
      "2023-04-17 12:32:56.088340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61abd3700 of size 147456 next 235\n",
      "2023-04-17 12:32:56.088354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61abf7700 of size 16384 next 490\n",
      "2023-04-17 12:32:56.088372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61abfb700 of size 16384 next 158\n",
      "2023-04-17 12:32:56.088381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61abff700 of size 16384 next 60\n",
      "2023-04-17 12:32:56.088394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ac03700 of size 24576 next 523\n",
      "2023-04-17 12:32:56.088406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ac09700 of size 16384 next 180\n",
      "2023-04-17 12:32:56.088419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ac0d700 of size 16384 next 579\n",
      "2023-04-17 12:32:56.088434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ac11700 of size 16384 next 727\n",
      "2023-04-17 12:32:56.088447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ac15700 of size 16384 next 449\n",
      "2023-04-17 12:32:56.088461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ac19700 of size 172032 next 435\n",
      "2023-04-17 12:32:56.088473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ac43700 of size 1048576 next 170\n",
      "2023-04-17 12:32:56.088485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ad43700 of size 16384 next 370\n",
      "2023-04-17 12:32:56.088497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ad47700 of size 20480 next 785\n",
      "2023-04-17 12:32:56.088508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ad4c700 of size 147456 next 480\n",
      "2023-04-17 12:32:56.088519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ad70700 of size 258048 next 621\n",
      "2023-04-17 12:32:56.088530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adaf700 of size 16384 next 687\n",
      "2023-04-17 12:32:56.088544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adb3700 of size 16384 next 675\n",
      "2023-04-17 12:32:56.088557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adb7700 of size 16384 next 535\n",
      "2023-04-17 12:32:56.088569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adbb700 of size 16384 next 742\n",
      "2023-04-17 12:32:56.088580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adbf700 of size 16384 next 649\n",
      "2023-04-17 12:32:56.088592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adc3700 of size 16384 next 186\n",
      "2023-04-17 12:32:56.088613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adc7700 of size 16384 next 563\n",
      "2023-04-17 12:32:56.088624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adcb700 of size 16384 next 65\n",
      "2023-04-17 12:32:56.088635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adcf700 of size 16384 next 156\n",
      "2023-04-17 12:32:56.088647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61add3700 of size 16384 next 755\n",
      "2023-04-17 12:32:56.088658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61add7700 of size 147456 next 280\n",
      "2023-04-17 12:32:56.088669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adfb700 of size 16384 next 761\n",
      "2023-04-17 12:32:56.088680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61adff700 of size 16384 next 472\n",
      "2023-04-17 12:32:56.088692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ae03700 of size 16384 next 478\n",
      "2023-04-17 12:32:56.088703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ae07700 of size 16384 next 145\n",
      "2023-04-17 12:32:56.088714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ae0b700 of size 4096 next 622\n",
      "2023-04-17 12:32:56.088728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 61ae0c700 of size 40960 next 292\n",
      "2023-04-17 12:32:56.088741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ae16700 of size 147456 next 281\n",
      "2023-04-17 12:32:56.088753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ae3a700 of size 147456 next 610\n",
      "2023-04-17 12:32:56.088765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ae5e700 of size 147456 next 277\n",
      "2023-04-17 12:32:56.088779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ae82700 of size 147456 next 411\n",
      "2023-04-17 12:32:56.088791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aea6700 of size 4096 next 474\n",
      "2023-04-17 12:32:56.088804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aea7700 of size 256 next 408\n",
      "2023-04-17 12:32:56.088815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 61aea7800 of size 28416 next 537\n",
      "2023-04-17 12:32:56.088827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aeae700 of size 16384 next 8\n",
      "2023-04-17 12:32:56.088839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aeb2700 of size 16384 next 553\n",
      "2023-04-17 12:32:56.088854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aeb6700 of size 16384 next 215\n",
      "2023-04-17 12:32:56.088871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aeba700 of size 28672 next 243\n",
      "2023-04-17 12:32:56.088888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aec1700 of size 16384 next 663\n",
      "2023-04-17 12:32:56.088901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aec5700 of size 147456 next 549\n",
      "2023-04-17 12:32:56.088913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61aee9700 of size 147456 next 291\n",
      "2023-04-17 12:32:56.088925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61af0d700 of size 147456 next 285\n",
      "2023-04-17 12:32:56.088942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 61af31700 of size 729088 next 39\n",
      "2023-04-17 12:32:56.088956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61afe3700 of size 262144 next 425\n",
      "2023-04-17 12:32:56.088968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b023700 of size 16384 next 747\n",
      "2023-04-17 12:32:56.088980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b027700 of size 20480 next 278\n",
      "2023-04-17 12:32:56.088991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b02c700 of size 258048 next 228\n",
      "2023-04-17 12:32:56.089003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b06b700 of size 16384 next 702\n",
      "2023-04-17 12:32:56.089015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b06f700 of size 147456 next 502\n",
      "2023-04-17 12:32:56.089026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b093700 of size 16384 next 191\n",
      "2023-04-17 12:32:56.089037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b097700 of size 147456 next 762\n",
      "2023-04-17 12:32:56.089048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b0bb700 of size 16384 next 481\n",
      "2023-04-17 12:32:56.089061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b0bf700 of size 16384 next 61\n",
      "2023-04-17 12:32:56.089082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b0c3700 of size 16384 next 120\n",
      "2023-04-17 12:32:56.089098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b0c7700 of size 24576 next 743\n",
      "2023-04-17 12:32:56.089114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b0cd700 of size 147456 next 440\n",
      "2023-04-17 12:32:56.089126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b0f1700 of size 147456 next 348\n",
      "2023-04-17 12:32:56.089138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b115700 of size 258048 next 735\n",
      "2023-04-17 12:32:56.089152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b154700 of size 16384 next 355\n",
      "2023-04-17 12:32:56.089166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b158700 of size 229632 next 496\n",
      "2023-04-17 12:32:56.089179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b190800 of size 262144 next 625\n",
      "2023-04-17 12:32:56.089192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b1d0800 of size 880384 next 217\n",
      "2023-04-17 12:32:56.089206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2a7700 of size 16384 next 82\n",
      "2023-04-17 12:32:56.089219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2ab700 of size 16384 next 334\n",
      "2023-04-17 12:32:56.089232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2af700 of size 16384 next 264\n",
      "2023-04-17 12:32:56.089244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2b3700 of size 16384 next 499\n",
      "2023-04-17 12:32:56.089260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2b7700 of size 16384 next 394\n",
      "2023-04-17 12:32:56.089273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2bb700 of size 16384 next 437\n",
      "2023-04-17 12:32:56.089285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2bf700 of size 16384 next 89\n",
      "2023-04-17 12:32:56.089297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2c3700 of size 16384 next 527\n",
      "2023-04-17 12:32:56.089310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2c7700 of size 28672 next 445\n",
      "2023-04-17 12:32:56.089325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2ce700 of size 147456 next 749\n",
      "2023-04-17 12:32:56.089338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b2f2700 of size 147456 next 127\n",
      "2023-04-17 12:32:56.089350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b316700 of size 147456 next 171\n",
      "2023-04-17 12:32:56.089362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b33a700 of size 16384 next 414\n",
      "2023-04-17 12:32:56.089374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b33e700 of size 147456 next 594\n",
      "2023-04-17 12:32:56.089390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b362700 of size 16384 next 704\n",
      "2023-04-17 12:32:56.089403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b366700 of size 16384 next 307\n",
      "2023-04-17 12:32:56.089415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b36a700 of size 16384 next 482\n",
      "2023-04-17 12:32:56.089426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b36e700 of size 16384 next 681\n",
      "2023-04-17 12:32:56.089438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b372700 of size 16384 next 265\n",
      "2023-04-17 12:32:56.089450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b376700 of size 16384 next 113\n",
      "2023-04-17 12:32:56.089462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b37a700 of size 28672 next 452\n",
      "2023-04-17 12:32:56.089474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b381700 of size 147456 next 251\n",
      "2023-04-17 12:32:56.089486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b3a5700 of size 147456 next 306\n",
      "2023-04-17 12:32:56.089497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b3c9700 of size 16384 next 446\n",
      "2023-04-17 12:32:56.089511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b3cd700 of size 16384 next 628\n",
      "2023-04-17 12:32:56.089523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b3d1700 of size 16384 next 495\n",
      "2023-04-17 12:32:56.089534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b3d5700 of size 24576 next 91\n",
      "2023-04-17 12:32:56.089546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b3db700 of size 163840 next 94\n",
      "2023-04-17 12:32:56.089563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b403700 of size 16384 next 218\n",
      "2023-04-17 12:32:56.089576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b407700 of size 147456 next 331\n",
      "2023-04-17 12:32:56.089588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b42b700 of size 276992 next 188\n",
      "2023-04-17 12:32:56.089601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61b46f100 of size 73754112 next 361\n",
      "2023-04-17 12:32:56.089613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 61fac5700 of size 3407872 next 671\n",
      "2023-04-17 12:32:56.089625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61fe05700 of size 446720 next 234\n",
      "2023-04-17 12:32:56.089637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61fe72800 of size 147456 next 298\n",
      "2023-04-17 12:32:56.089649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61fe96800 of size 147456 next 134\n",
      "2023-04-17 12:32:56.089662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61feba800 of size 147456 next 58\n",
      "2023-04-17 12:32:56.089673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61fede800 of size 147456 next 423\n",
      "2023-04-17 12:32:56.089685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ff02800 of size 290560 next 706\n",
      "2023-04-17 12:32:56.089698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ff49700 of size 524288 next 253\n",
      "2023-04-17 12:32:56.089711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 61ffc9700 of size 524288 next 259\n",
      "2023-04-17 12:32:56.089723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 620049700 of size 1048576 next 768\n",
      "2023-04-17 12:32:56.089735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 620149700 of size 2056192 next 422\n",
      "2023-04-17 12:32:56.089748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 62033f700 of size 256 next 328\n",
      "2023-04-17 12:32:56.089761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 62033f800 of size 256 next 268\n",
      "2023-04-17 12:32:56.089774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 62033f900 of size 708352 next 626\n",
      "2023-04-17 12:32:56.089786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 6203ec800 of size 59158272 next 403\n",
      "2023-04-17 12:32:56.089798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57700 of size 256 next 434\n",
      "2023-04-17 12:32:56.089810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57800 of size 256 next 722\n",
      "2023-04-17 12:32:56.089822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57900 of size 256 next 198\n",
      "2023-04-17 12:32:56.089835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57a00 of size 256 next 299\n",
      "2023-04-17 12:32:56.089846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57b00 of size 256 next 514\n",
      "2023-04-17 12:32:56.089858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57c00 of size 256 next 685\n",
      "2023-04-17 12:32:56.089869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57d00 of size 256 next 616\n",
      "2023-04-17 12:32:56.089881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57e00 of size 256 next 426\n",
      "2023-04-17 12:32:56.089893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c57f00 of size 256 next 726\n",
      "2023-04-17 12:32:56.089909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 623c58000 of size 256 next 574\n",
      "2023-04-17 12:32:56.089927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58100 of size 256 next 692\n",
      "2023-04-17 12:32:56.089939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58200 of size 256 next 128\n",
      "2023-04-17 12:32:56.089954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58300 of size 256 next 69\n",
      "2023-04-17 12:32:56.089967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58400 of size 256 next 573\n",
      "2023-04-17 12:32:56.089979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58500 of size 256 next 566\n",
      "2023-04-17 12:32:56.089990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58600 of size 256 next 679\n",
      "2023-04-17 12:32:56.090002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58700 of size 256 next 400\n",
      "2023-04-17 12:32:56.090013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58800 of size 256 next 713\n",
      "2023-04-17 12:32:56.090023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58900 of size 256 next 187\n",
      "2023-04-17 12:32:56.090034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58a00 of size 256 next 592\n",
      "2023-04-17 12:32:56.090044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58b00 of size 256 next 108\n",
      "2023-04-17 12:32:56.090056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58c00 of size 256 next 578\n",
      "2023-04-17 12:32:56.090067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58d00 of size 256 next 179\n",
      "2023-04-17 12:32:56.090079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58e00 of size 256 next 216\n",
      "2023-04-17 12:32:56.090091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c58f00 of size 256 next 75\n",
      "2023-04-17 12:32:56.090103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59000 of size 256 next 239\n",
      "2023-04-17 12:32:56.090114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59100 of size 256 next 337\n",
      "2023-04-17 12:32:56.090127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59200 of size 256 next 656\n",
      "2023-04-17 12:32:56.090139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59300 of size 256 next 356\n",
      "2023-04-17 12:32:56.090150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59400 of size 256 next 352\n",
      "2023-04-17 12:32:56.090161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59500 of size 256 next 784\n",
      "2023-04-17 12:32:56.090173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59600 of size 256 next 57\n",
      "2023-04-17 12:32:56.090184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59700 of size 256 next 165\n",
      "2023-04-17 12:32:56.090197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 623c59800 of size 158072576 next 96\n",
      "2023-04-17 12:32:56.090212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 62d319700 of size 3328 next 72\n",
      "2023-04-17 12:32:56.090224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 62d31a400 of size 16777216 next 407\n",
      "2023-04-17 12:32:56.090236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 62e31a400 of size 8388608 next 640\n",
      "2023-04-17 12:32:56.090248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 62eb1a400 of size 22768384 next 777\n",
      "2023-04-17 12:32:56.090261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 6300d0f00 of size 256 next 430\n",
      "2023-04-17 12:32:56.090274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 6300d1000 of size 7744000 next 68\n",
      "2023-04-17 12:32:56.090285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630833a00 of size 256 next 105\n",
      "2023-04-17 12:32:56.090297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630833b00 of size 256 next 409\n",
      "2023-04-17 12:32:56.090307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630833c00 of size 256 next 531\n",
      "2023-04-17 12:32:56.090319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630833d00 of size 256 next 604\n",
      "2023-04-17 12:32:56.090330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630833e00 of size 256 next 62\n",
      "2023-04-17 12:32:56.090341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630833f00 of size 256 next 772\n",
      "2023-04-17 12:32:56.090352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630834000 of size 256 next 586\n",
      "2023-04-17 12:32:56.090363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630834100 of size 256 next 379\n",
      "2023-04-17 12:32:56.090376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 630834200 of size 8388608 next 293\n",
      "2023-04-17 12:32:56.090388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 631034200 of size 8388608 next 368\n",
      "2023-04-17 12:32:56.090401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 631834200 of size 4194304 next 124\n",
      "2023-04-17 12:32:56.090414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 631c34200 of size 4194304 next 709\n",
      "2023-04-17 12:32:56.090427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 632034200 of size 50331648 next 323\n",
      "2023-04-17 12:32:56.090439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 635034200 of size 37748736 next 427\n",
      "2023-04-17 12:32:56.090452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 637434200 of size 44301568 next 104\n",
      "2023-04-17 12:32:56.090464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e73f00 of size 256 next 662\n",
      "2023-04-17 12:32:56.090476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e74000 of size 4096 next 652\n",
      "2023-04-17 12:32:56.090489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e75000 of size 6144 next 545\n",
      "2023-04-17 12:32:56.090501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e76800 of size 3840 next 614\n",
      "2023-04-17 12:32:56.090513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77700 of size 256 next 343\n",
      "2023-04-17 12:32:56.090525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77800 of size 256 next 660\n",
      "2023-04-17 12:32:56.090537: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77900 of size 256 next 185\n",
      "2023-04-17 12:32:56.090548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77a00 of size 256 next 97\n",
      "2023-04-17 12:32:56.090560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77b00 of size 256 next 296\n",
      "2023-04-17 12:32:56.090571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77c00 of size 256 next 73\n",
      "2023-04-17 12:32:56.090583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77d00 of size 256 next 203\n",
      "2023-04-17 12:32:56.090595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77e00 of size 256 next 404\n",
      "2023-04-17 12:32:56.090606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e77f00 of size 256 next 77\n",
      "2023-04-17 12:32:56.090618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e78000 of size 256 next 723\n",
      "2023-04-17 12:32:56.090629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e78100 of size 256 next 667\n",
      "2023-04-17 12:32:56.090641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e78200 of size 256 next 121\n",
      "2023-04-17 12:32:56.090652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e78300 of size 256 next 673\n",
      "2023-04-17 12:32:56.090664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e78400 of size 256 next 126\n",
      "2023-04-17 12:32:56.090676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e78500 of size 16384 next 241\n",
      "2023-04-17 12:32:56.090687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e7c500 of size 16384 next 51\n",
      "2023-04-17 12:32:56.090698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e80500 of size 16384 next 418\n",
      "2023-04-17 12:32:56.090710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e84500 of size 16384 next 173\n",
      "2023-04-17 12:32:56.090722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e88500 of size 4096 next 492\n",
      "2023-04-17 12:32:56.090736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e89500 of size 22272 next 304\n",
      "2023-04-17 12:32:56.090766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 639e8ec00 of size 250165248 next 53\n",
      "2023-04-17 12:32:56.090785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 648d22400 of size 150994944 next 781\n",
      "2023-04-17 12:32:56.090803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 651d22400 of size 16777216 next 230\n",
      "2023-04-17 12:32:56.090815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 652d22400 of size 4194304 next 36\n",
      "2023-04-17 12:32:56.090826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 653122400 of size 4194304 next 603\n",
      "2023-04-17 12:32:56.090837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 653522400 of size 4194304 next 115\n",
      "2023-04-17 12:32:56.090847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 653922400 of size 4194304 next 697\n",
      "2023-04-17 12:32:56.090858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 653d22400 of size 37748736 next 63\n",
      "2023-04-17 12:32:56.090869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 656122400 of size 37748736 next 227\n",
      "2023-04-17 12:32:56.090881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 658522400 of size 37748736 next 390\n",
      "2023-04-17 12:32:56.090892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 65a922400 of size 37748736 next 133\n",
      "2023-04-17 12:32:56.090903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 65cd22400 of size 4194304 next 273\n",
      "2023-04-17 12:32:56.090914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 65d122400 of size 4194304 next 680\n",
      "2023-04-17 12:32:56.090924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 65d522400 of size 4194304 next 717\n",
      "2023-04-17 12:32:56.090935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 65d922400 of size 4194304 next 666\n",
      "2023-04-17 12:32:56.090946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 65dd22400 of size 37748736 next 395\n",
      "2023-04-17 12:32:56.090957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 660122400 of size 37748736 next 196\n",
      "2023-04-17 12:32:56.090968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 662522400 of size 37748736 next 548\n",
      "2023-04-17 12:32:56.090979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 664922400 of size 37748736 next 71\n",
      "2023-04-17 12:32:56.090989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 666d22400 of size 4194304 next 665\n",
      "2023-04-17 12:32:56.091000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 667122400 of size 4194304 next 738\n",
      "2023-04-17 12:32:56.091011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 667522400 of size 4194304 next 338\n",
      "2023-04-17 12:32:56.091022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 667922400 of size 4194304 next 424\n",
      "2023-04-17 12:32:56.091033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 667d22400 of size 37748736 next 485\n",
      "2023-04-17 12:32:56.091045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 66a122400 of size 37748736 next 465\n",
      "2023-04-17 12:32:56.091056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 66c522400 of size 37748736 next 624\n",
      "2023-04-17 12:32:56.091066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 66e922400 of size 37748736 next 664\n",
      "2023-04-17 12:32:56.091077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 670d22400 of size 4194304 next 643\n",
      "2023-04-17 12:32:56.091088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 671122400 of size 4194304 next 488\n",
      "2023-04-17 12:32:56.091098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 671522400 of size 4194304 next 211\n",
      "2023-04-17 12:32:56.091110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 671922400 of size 4194304 next 539\n",
      "2023-04-17 12:32:56.091120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 671d22400 of size 37748736 next 454\n",
      "2023-04-17 12:32:56.091131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 674122400 of size 37748736 next 195\n",
      "2023-04-17 12:32:56.091145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 676522400 of size 37748736 next 199\n",
      "2023-04-17 12:32:56.091155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 678922400 of size 37748736 next 456\n",
      "2023-04-17 12:32:56.091166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 67ad22400 of size 4194304 next 443\n",
      "2023-04-17 12:32:56.091177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 67b122400 of size 4194304 next 21\n",
      "2023-04-17 12:32:56.091188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 67b522400 of size 4194304 next 276\n",
      "2023-04-17 12:32:56.091199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 67b922400 of size 4194304 next 106\n",
      "2023-04-17 12:32:56.091209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 67bd22400 of size 37748736 next 192\n",
      "2023-04-17 12:32:56.091220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 67e122400 of size 37748736 next 369\n",
      "2023-04-17 12:32:56.091231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 680522400 of size 37748736 next 141\n",
      "2023-04-17 12:32:56.091242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 682922400 of size 37748736 next 85\n",
      "2023-04-17 12:32:56.091253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 684d22400 of size 4194304 next 76\n",
      "2023-04-17 12:32:56.091264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 685122400 of size 4194304 next 288\n",
      "2023-04-17 12:32:56.091275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 685522400 of size 4194304 next 513\n",
      "2023-04-17 12:32:56.091287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 685922400 of size 4194304 next 711\n",
      "2023-04-17 12:32:56.091298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 685d22400 of size 37748736 next 787\n",
      "2023-04-17 12:32:56.091308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 688122400 of size 37748736 next 595\n",
      "2023-04-17 12:32:56.091321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 68a522400 of size 37748736 next 367\n",
      "2023-04-17 12:32:56.091332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 68c922400 of size 37748736 next 737\n",
      "2023-04-17 12:32:56.091343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 68ed22400 of size 4194304 next 391\n",
      "2023-04-17 12:32:56.091354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 68f122400 of size 4194304 next 232\n",
      "2023-04-17 12:32:56.091365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 68f522400 of size 4194304 next 500\n",
      "2023-04-17 12:32:56.091377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 68f922400 of size 4194304 next 374\n",
      "2023-04-17 12:32:56.091389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 68fd22400 of size 57269248 next 18446744073709551615\n",
      "2023-04-17 12:32:56.091401: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-04-17 12:32:56.091423: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 219 Chunks of size 256 totalling 54.8KiB\n",
      "2023-04-17 12:32:56.091438: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-04-17 12:32:56.091451: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 2048 totalling 8.0KiB\n",
      "2023-04-17 12:32:56.091464: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2560 totalling 2.5KiB\n",
      "2023-04-17 12:32:56.091476: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 3072 totalling 6.0KiB\n",
      "2023-04-17 12:32:56.091489: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3328 totalling 3.2KiB\n",
      "2023-04-17 12:32:56.091501: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2023-04-17 12:32:56.091514: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 4096 totalling 32.0KiB\n",
      "2023-04-17 12:32:56.091527: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4864 totalling 4.8KiB\n",
      "2023-04-17 12:32:56.091542: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5632 totalling 5.5KiB\n",
      "2023-04-17 12:32:56.091554: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 6144 totalling 12.0KiB\n",
      "2023-04-17 12:32:56.091567: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 8192 totalling 8.0KiB\n",
      "2023-04-17 12:32:56.091579: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 11520 totalling 11.2KiB\n",
      "2023-04-17 12:32:56.091592: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 12288 totalling 24.0KiB\n",
      "2023-04-17 12:32:56.091615: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12544 totalling 12.2KiB\n",
      "2023-04-17 12:32:56.091628: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 57 Chunks of size 16384 totalling 912.0KiB\n",
      "2023-04-17 12:32:56.091642: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 18688 totalling 18.2KiB\n",
      "2023-04-17 12:32:56.091654: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 20480 totalling 60.0KiB\n",
      "2023-04-17 12:32:56.091667: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 22272 totalling 21.8KiB\n",
      "2023-04-17 12:32:56.091679: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 22528 totalling 22.0KiB\n",
      "2023-04-17 12:32:56.091693: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 22784 totalling 22.2KiB\n",
      "2023-04-17 12:32:56.091707: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 24576 totalling 72.0KiB\n",
      "2023-04-17 12:32:56.091721: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25856 totalling 25.2KiB\n",
      "2023-04-17 12:32:56.091734: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 28672 totalling 84.0KiB\n",
      "2023-04-17 12:32:56.091747: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 29 Chunks of size 147456 totalling 4.08MiB\n",
      "2023-04-17 12:32:56.091761: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 163840 totalling 160.0KiB\n",
      "2023-04-17 12:32:56.091774: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 172032 totalling 168.0KiB\n",
      "2023-04-17 12:32:56.091788: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 229632 totalling 224.2KiB\n",
      "2023-04-17 12:32:56.091800: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 258048 totalling 756.0KiB\n",
      "2023-04-17 12:32:56.091813: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 262144 totalling 768.0KiB\n",
      "2023-04-17 12:32:56.091828: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 276992 totalling 270.5KiB\n",
      "2023-04-17 12:32:56.091841: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 290560 totalling 283.8KiB\n",
      "2023-04-17 12:32:56.091855: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 394752 totalling 385.5KiB\n",
      "2023-04-17 12:32:56.091868: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 446720 totalling 436.2KiB\n",
      "2023-04-17 12:32:56.091881: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 524288 totalling 1.00MiB\n",
      "2023-04-17 12:32:56.091894: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 708352 totalling 691.8KiB\n",
      "2023-04-17 12:32:56.091908: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 880384 totalling 859.8KiB\n",
      "2023-04-17 12:32:56.091919: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1048576 totalling 2.00MiB\n",
      "2023-04-17 12:32:56.091932: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1309952 totalling 1.25MiB\n",
      "2023-04-17 12:32:56.091944: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2056192 totalling 1.96MiB\n",
      "2023-04-17 12:32:56.091958: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 30 Chunks of size 4194304 totalling 120.00MiB\n",
      "2023-04-17 12:32:56.091971: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7744000 totalling 7.38MiB\n",
      "2023-04-17 12:32:56.091983: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 8388608 totalling 24.00MiB\n",
      "2023-04-17 12:32:56.091995: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 16777216 totalling 32.00MiB\n",
      "2023-04-17 12:32:56.092008: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 22768384 totalling 21.71MiB\n",
      "2023-04-17 12:32:56.092021: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 32178176 totalling 30.69MiB\n",
      "2023-04-17 12:32:56.092034: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 25 Chunks of size 37748736 totalling 900.00MiB\n",
      "2023-04-17 12:32:56.092047: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 44301568 totalling 42.25MiB\n",
      "2023-04-17 12:32:56.092060: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 50331648 totalling 48.00MiB\n",
      "2023-04-17 12:32:56.092074: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 56623104 totalling 54.00MiB\n",
      "2023-04-17 12:32:56.092086: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 57269248 totalling 54.62MiB\n",
      "2023-04-17 12:32:56.092099: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 59158272 totalling 56.42MiB\n",
      "2023-04-17 12:32:56.092111: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 59622912 totalling 56.86MiB\n",
      "2023-04-17 12:32:56.092124: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 73754112 totalling 70.34MiB\n",
      "2023-04-17 12:32:56.092136: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 75136768 totalling 71.66MiB\n",
      "2023-04-17 12:32:56.092149: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 150994944 totalling 144.00MiB\n",
      "2023-04-17 12:32:56.092161: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 158072576 totalling 150.75MiB\n",
      "2023-04-17 12:32:56.092176: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 163494400 totalling 155.92MiB\n",
      "2023-04-17 12:32:56.092189: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 250165248 totalling 238.58MiB\n",
      "2023-04-17 12:32:56.092202: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 2.24GiB\n",
      "2023-04-17 12:32:56.092216: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 2411462656 memory_limit_: 2411462656 available bytes: 0 curr_region_allocation_bytes_: 4822925312\n",
      "2023-04-17 12:32:56.092234: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      2411462656\n",
      "InUse:                      2407256064\n",
      "MaxInUse:                   2407256320\n",
      "NumAllocs:                    12235327\n",
      "MaxAllocSize:                250165248\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-04-17 12:32:56.092296: W tensorflow/tsl/framework/bfc_allocator.cc:497] *********************************************xxx****************************************************\n",
      "2023-04-17 12:32:56.092334: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at split_op.cc:307 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[9216,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2023-04-17 12:32:56.092373: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[9216,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{function_node sequential_12_lstm_10_while_body_197876_rewritten}}{{node sequential_12/lstm_10/while/lstm_cell_10/split}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_12/lstm_10/while/lstm_cell_10/split' defined at (most recent call last):\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_11781/1139072085.py\", line 1, in <module>\n      model.fit(train_dataset, epochs=100, validation_data=valid_dataset)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/rnn/base_rnn.py\", line 556, in __call__\n      return super().__call__(inputs, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/rnn/lstm.py\", line 625, in call\n      last_output, outputs, states = backend.rnn(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5126, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5089, in _step\n      output, new_states = step_function(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/rnn/lstm.py\", line 623, in step\n      return self.cell(inputs, states, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/rnn/lstm.py\", line 295, in call\n      k_i, k_f, k_c, k_o = tf.split(\nNode: 'sequential_12/lstm_10/while/lstm_cell_10/split'\nOOM when allocating tensor with shape[9216,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_12/lstm_10/while/lstm_cell_10/split}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_201960]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalid_dataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_12/lstm_10/while/lstm_cell_10/split' defined at (most recent call last):\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_11781/1139072085.py\", line 1, in <module>\n      model.fit(train_dataset, epochs=100, validation_data=valid_dataset)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/rnn/base_rnn.py\", line 556, in __call__\n      return super().__call__(inputs, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/rnn/lstm.py\", line 625, in call\n      last_output, outputs, states = backend.rnn(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5126, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5089, in _step\n      output, new_states = step_function(\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/rnn/lstm.py\", line 623, in step\n      return self.cell(inputs, states, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/rnn/lstm.py\", line 295, in call\n      k_i, k_f, k_c, k_o = tf.split(\nNode: 'sequential_12/lstm_10/while/lstm_cell_10/split'\nOOM when allocating tensor with shape[9216,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_12/lstm_10/while/lstm_cell_10/split}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_201960]"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=100, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 19:56:48.845634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-17 19:56:48.846031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 10, 9216), found shape=(None, None, 10, 9216)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prediction_test \u001b[39m=\u001b[39m cnnrnn\u001b[39m.\u001b[39;49mpredict(test_dataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filey0pa73z4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/christian/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 10, 9216), found shape=(None, None, 10, 9216)\n"
     ]
    }
   ],
   "source": [
    "prediction_test = cnnrnn.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test[1]\n",
    "y_pred = np.argmax(prediction_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 1, 4, 1, 4, 0, 0, 3, 5, 0, 1, 1, 2, 4, 2, 4, 4, 1, 4,\n",
       "       0, 2, 0, 2, 1, 2, 1, 5, 2, 2, 2, 1, 1, 0, 1, 4, 3, 2, 0, 4, 1, 1,\n",
       "       1, 2, 4, 4, 4, 0, 3, 1, 5, 4, 1, 3, 5, 4, 2, 1, 0, 5], dtype=int64)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27856\\1367598076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \"\"\"\n\u001b[1;32m--> 317\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val,prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "\n",
    "    frame_features_input = tf.keras.Input((SEQUENCE_LENGTH, longest_feature))\n",
    "    mask_input = tf.keras.Input((SEQUENCE_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://tf.keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = tf.keras.layers.GRU(16, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = tf.keras.layers.GRU(8)(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = tf.keras.layers.Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = tf.keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_4\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 10, 9216) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27856\\4016207678.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mseq_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sequence_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m history = seq_model.fit(train_dataset,\n\u001b[0m\u001b[0;32m      4\u001b[0m                         epochs=EPOCHS, validation_data= valid_dataset)\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_4\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 10, 9216) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "seq_model = get_sequence_model()\n",
    "history = seq_model.fit(train_dataset,\n",
    "                        epochs=EPOCHS, validation_data= valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 10, 9216)]   0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " gru_19 (GRU)                   (None, 10, 16)       443232      ['input_8[0][0]',                \n",
      "                                                                  'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " gru_20 (GRU)                   (None, 8)            624         ['gru_19[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 8)            0           ['gru_20[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 8)            72          ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 6)            54          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 443,982\n",
      "Trainable params: 443,982\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    lrate = hp.Float('lrate', 1e-4, 1e-1, sampling='log')\n",
    "    l1 = 0\n",
    "    l2 = hp.Choice('l2',  values=[0.0, 1e-1, 1e-2, 1e-3, 1e-4])\n",
    "    num_rnn = hp.Int('num_rnn', 32,512,32)\n",
    "    num_hidden = hp.Int('num_hidden', 32,512,32)\n",
    "    regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Masking(mask_value=0.))\n",
    "    model.add(tf.keras.layers.GRU(512, dropout=0.5,return_sequences=True, recurrent_dropout=0.5, input_shape= [SEQUENCE_LENGTH, longest_feature]))\n",
    "    model.add(tf.keras.layers.GRU(256, dropout=0.5, recurrent_dropout=0.5))\n",
    "    #model.add(tf.keras.layers.Dense(num_hidden, activation='relu', kernel_regularizer=regularizer))\n",
    "    #model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(6, activation='softmax', kernel_regularizer=regularizer))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                  loss='categorical_crossentropy', metrics=[precision,recall,'accuracy', 'top_k_categorical_accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=keras_tuner.Objective('val_accuracy', 'max'),\n",
    "    max_trials = 10,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.093061          |0.093061          |lrate\n",
      "0.01              |0.01              |l2\n",
      "64                |64                |num_rnn\n",
      "160               |160               |num_hidden\n",
      "\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 80s 597ms/step - loss: 8.8756 - Precision: 0.2402 - Recall: 0.1536 - accuracy: 0.2317 - top_k_categorical_accuracy: 0.8659 - val_loss: 5.7034 - val_Precision: 0.1803 - val_Recall: 0.1774 - val_accuracy: 0.1774 - val_top_k_categorical_accuracy: 0.9194\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 86s 696ms/step - loss: 6.3693 - Precision: 0.1916 - Recall: 0.1667 - accuracy: 0.1789 - top_k_categorical_accuracy: 0.8374 - val_loss: 4.7148 - val_Precision: 0.2581 - val_Recall: 0.2581 - val_accuracy: 0.2581 - val_top_k_categorical_accuracy: 0.8548\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 88s 718ms/step - loss: 7.1011 - Precision: 0.1739 - Recall: 0.1626 - accuracy: 0.1707 - top_k_categorical_accuracy: 0.8455 - val_loss: 6.3879 - val_Precision: 0.2581 - val_Recall: 0.2581 - val_accuracy: 0.2581 - val_top_k_categorical_accuracy: 0.9032\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 71s 581ms/step - loss: 7.3857 - Precision: 0.2325 - Recall: 0.2154 - accuracy: 0.2276 - top_k_categorical_accuracy: 0.8659 - val_loss: 4.6771 - val_Precision: 0.2581 - val_Recall: 0.2581 - val_accuracy: 0.2581 - val_top_k_categorical_accuracy: 0.8548\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 74s 603ms/step - loss: 8.7636 - Precision: 0.2185 - Recall: 0.2114 - accuracy: 0.2195 - top_k_categorical_accuracy: 0.9065 - val_loss: 10.6151 - val_Precision: 0.2581 - val_Recall: 0.2581 - val_accuracy: 0.2581 - val_top_k_categorical_accuracy: 0.9194\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 69s 559ms/step - loss: 7.1684 - Precision: 0.2112 - Recall: 0.1992 - accuracy: 0.2073 - top_k_categorical_accuracy: 0.8740 - val_loss: 4.7848 - val_Precision: 0.0806 - val_Recall: 0.0806 - val_accuracy: 0.0806 - val_top_k_categorical_accuracy: 0.8548\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 69s 558ms/step - loss: 7.6799 - Precision: 0.2203 - Recall: 0.2114 - accuracy: 0.2195 - top_k_categorical_accuracy: 0.8537 - val_loss: 4.9996 - val_Precision: 0.1935 - val_Recall: 0.1935 - val_accuracy: 0.1935 - val_top_k_categorical_accuracy: 0.9194\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 63s 514ms/step - loss: 8.1882 - Precision: 0.1864 - Recall: 0.1789 - accuracy: 0.1829 - top_k_categorical_accuracy: 0.8902 - val_loss: 4.7328 - val_Precision: 0.2581 - val_Recall: 0.2581 - val_accuracy: 0.2581 - val_top_k_categorical_accuracy: 0.9032\n",
      "Epoch 9/10\n",
      " 78/123 [==================>...........] - ETA: 21s - loss: 6.8823 - Precision: 0.1642 - Recall: 0.1410 - accuracy: 0.1538 - top_k_categorical_accuracy: 0.7756"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27856\\39513438.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tuner.search(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[0;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[0;32m    216\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HyperModel.fit()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \"\"\"\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdr03\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1683\u001b[0m                         ):\n\u001b[0;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    924\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m       (concrete_function,\n\u001b[0;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1756\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    train_dataset, validation_data= valid_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
